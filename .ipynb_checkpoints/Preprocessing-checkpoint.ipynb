{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5a368c2-9a64-4db7-aa24-c0e7fa1e314c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pyspark in c:\\users\\shlok\\appdata\\roaming\\python\\python311\\site-packages (3.4.0)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in c:\\users\\shlok\\appdata\\roaming\\python\\python311\\site-packages (from pyspark) (0.10.9.7)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pymongo in c:\\users\\shlok\\appdata\\roaming\\python\\python311\\site-packages (4.3.3)\n",
      "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in c:\\users\\shlok\\appdata\\roaming\\python\\python311\\site-packages (from pymongo) (2.3.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in c:\\users\\shlok\\appdata\\roaming\\python\\python311\\site-packages (2.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\shlok\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\shlok\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\shlok\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\shlok\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\shlok\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: geopy in c:\\users\\shlok\\appdata\\roaming\\python\\python311\\site-packages (2.3.0)\n",
      "Requirement already satisfied: geographiclib<3,>=1.52 in c:\\users\\shlok\\appdata\\roaming\\python\\python311\\site-packages (from geopy) (2.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: folium in c:\\users\\shlok\\appdata\\roaming\\python\\python311\\site-packages (0.14.0)\n",
      "Requirement already satisfied: branca>=0.6.0 in c:\\users\\shlok\\appdata\\roaming\\python\\python311\\site-packages (from folium) (0.6.0)\n",
      "Requirement already satisfied: jinja2>=2.9 in c:\\users\\shlok\\appdata\\roaming\\python\\python311\\site-packages (from folium) (3.1.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\shlok\\appdata\\roaming\\python\\python311\\site-packages (from folium) (1.24.3)\n",
      "Requirement already satisfied: requests in c:\\users\\shlok\\appdata\\roaming\\python\\python311\\site-packages (from folium) (2.30.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\shlok\\appdata\\roaming\\python\\python311\\site-packages (from jinja2>=2.9->folium) (2.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\shlok\\appdata\\roaming\\python\\python311\\site-packages (from requests->folium) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shlok\\appdata\\roaming\\python\\python311\\site-packages (from requests->folium) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\shlok\\appdata\\roaming\\python\\python311\\site-packages (from requests->folium) (2.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shlok\\appdata\\roaming\\python\\python311\\site-packages (from requests->folium) (2022.12.7)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: haversine in c:\\users\\shlok\\appdata\\roaming\\python\\python311\\site-packages (2.8.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark\n",
    "!pip install pymongo\n",
    "!pip install pandas\n",
    "!pip install geopy\n",
    "!pip install folium\n",
    "!pip install haversine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "969f92cb-67c1-4230-a826-b416185fd9d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Java gateway process exited before sending its port number",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 12\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# set Spark configuration properties\u001b[39;00m\n\u001b[0;32m      9\u001b[0m conf \u001b[38;5;241m=\u001b[39m SparkConf() \\\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;241m.\u001b[39mset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspark.driver.memory\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m4g\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 12\u001b[0m sc \u001b[38;5;241m=\u001b[39m \u001b[43mpyspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSparkContext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m spark \u001b[38;5;241m=\u001b[39m pyspark\u001b[38;5;241m.\u001b[39mSQLContext\u001b[38;5;241m.\u001b[39mgetOrCreate(sc)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pyspark\\context.py:198\u001b[0m, in \u001b[0;36mSparkContext.__init__\u001b[1;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls, udf_profiler_cls, memory_profiler_cls)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gateway \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m gateway\u001b[38;5;241m.\u001b[39mgateway_parameters\u001b[38;5;241m.\u001b[39mauth_token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    194\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are trying to pass an insecure Py4j gateway to Spark. This\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    195\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is not allowed as it is a security risk.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    196\u001b[0m     )\n\u001b[1;32m--> 198\u001b[0m \u001b[43mSparkContext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ensure_initialized\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgateway\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgateway\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_init(\n\u001b[0;32m    201\u001b[0m         master,\n\u001b[0;32m    202\u001b[0m         appName,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    212\u001b[0m         memory_profiler_cls,\n\u001b[0;32m    213\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pyspark\\context.py:432\u001b[0m, in \u001b[0;36mSparkContext._ensure_initialized\u001b[1;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[0;32m    430\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    431\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_gateway:\n\u001b[1;32m--> 432\u001b[0m         SparkContext\u001b[38;5;241m.\u001b[39m_gateway \u001b[38;5;241m=\u001b[39m gateway \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mlaunch_gateway\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    433\u001b[0m         SparkContext\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;241m=\u001b[39m SparkContext\u001b[38;5;241m.\u001b[39m_gateway\u001b[38;5;241m.\u001b[39mjvm\n\u001b[0;32m    435\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m instance:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pyspark\\java_gateway.py:106\u001b[0m, in \u001b[0;36mlaunch_gateway\u001b[1;34m(conf, popen_kwargs)\u001b[0m\n\u001b[0;32m    103\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.1\u001b[39m)\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(conn_info_file):\n\u001b[1;32m--> 106\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJava gateway process exited before sending its port number\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(conn_info_file, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m info:\n\u001b[0;32m    109\u001b[0m     gateway_port \u001b[38;5;241m=\u001b[39m read_int(info)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Java gateway process exited before sending its port number"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf\n",
    "import os\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SQLContext\n",
    "import pyspark\n",
    "\n",
    "# set Spark configuration properties\n",
    "conf = SparkConf() \\\n",
    "    .set('spark.driver.memory', '4g')\n",
    "\n",
    "sc = pyspark.SparkContext(conf=conf)\n",
    "spark = pyspark.SQLContext.getOrCreate(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45dd59d1-4152-4b52-a35c-c0df69c70ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the NYPD Complaints dataset into a Spark DataFrame\n",
    "complaintsDF = spark.read.csv(\"NYPD_Complaint_Data_Historic.csv\", header=True, inferSchema=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d264436-da25-431d-8beb-281ee64e4978",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#only using half the dataset as its too big and taking too long and crashing sometimes on my PC\n",
    "sampledDF = complaintsDF.sample(withReplacement=False, fraction=0.25, seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890f20cd-4530-4d2e-aab7-e8fa19925667",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = sampledDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e9212e-cb36-4dd3-94ba-40cc881c1a46",
   "metadata": {},
   "source": [
    "## DATA PROFILING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d4ea5e8-5ab4-4ca1-ab5e-0b21ca7176c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CMPLNT_NUM: integer (nullable = true)\n",
      " |-- CMPLNT_FR_DT: string (nullable = true)\n",
      " |-- CMPLNT_FR_TM: timestamp (nullable = true)\n",
      " |-- CMPLNT_TO_DT: string (nullable = true)\n",
      " |-- CMPLNT_TO_TM: string (nullable = true)\n",
      " |-- ADDR_PCT_CD: integer (nullable = true)\n",
      " |-- RPT_DT: string (nullable = true)\n",
      " |-- KY_CD: integer (nullable = true)\n",
      " |-- OFNS_DESC: string (nullable = true)\n",
      " |-- PD_CD: integer (nullable = true)\n",
      " |-- PD_DESC: string (nullable = true)\n",
      " |-- CRM_ATPT_CPTD_CD: string (nullable = true)\n",
      " |-- LAW_CAT_CD: string (nullable = true)\n",
      " |-- BORO_NM: string (nullable = true)\n",
      " |-- LOC_OF_OCCUR_DESC: string (nullable = true)\n",
      " |-- PREM_TYP_DESC: string (nullable = true)\n",
      " |-- JURIS_DESC: string (nullable = true)\n",
      " |-- JURISDICTION_CODE: integer (nullable = true)\n",
      " |-- PARKS_NM: string (nullable = true)\n",
      " |-- HADEVELOPT: string (nullable = true)\n",
      " |-- HOUSING_PSA: string (nullable = true)\n",
      " |-- X_COORD_CD: integer (nullable = true)\n",
      " |-- Y_COORD_CD: integer (nullable = true)\n",
      " |-- SUSP_AGE_GROUP: string (nullable = true)\n",
      " |-- SUSP_RACE: string (nullable = true)\n",
      " |-- SUSP_SEX: string (nullable = true)\n",
      " |-- TRANSIT_DISTRICT: integer (nullable = true)\n",
      " |-- Latitude: double (nullable = true)\n",
      " |-- Longitude: double (nullable = true)\n",
      " |-- Lat_Lon: string (nullable = true)\n",
      " |-- PATROL_BORO: string (nullable = true)\n",
      " |-- STATION_NAME: string (nullable = true)\n",
      " |-- VIC_AGE_GROUP: string (nullable = true)\n",
      " |-- VIC_RACE: string (nullable = true)\n",
      " |-- VIC_SEX: string (nullable = true)\n",
      "\n",
      "Number of rows:  1958512\n",
      "Number of columns:  35\n",
      "+----------+------------+-------------------+------------+------------+-----------+----------+-----+--------------------+-----+--------------------+----------------+-----------+---------+-----------------+-------------+----------------+-----------------+--------+----------+-----------+----------+----------+--------------+---------+--------+----------------+-----------------+------------------+--------------------+--------------------+------------+-------------+--------------+-------+\n",
      "|CMPLNT_NUM|CMPLNT_FR_DT|       CMPLNT_FR_TM|CMPLNT_TO_DT|CMPLNT_TO_TM|ADDR_PCT_CD|    RPT_DT|KY_CD|           OFNS_DESC|PD_CD|             PD_DESC|CRM_ATPT_CPTD_CD| LAW_CAT_CD|  BORO_NM|LOC_OF_OCCUR_DESC|PREM_TYP_DESC|      JURIS_DESC|JURISDICTION_CODE|PARKS_NM|HADEVELOPT|HOUSING_PSA|X_COORD_CD|Y_COORD_CD|SUSP_AGE_GROUP|SUSP_RACE|SUSP_SEX|TRANSIT_DISTRICT|         Latitude|         Longitude|             Lat_Lon|         PATROL_BORO|STATION_NAME|VIC_AGE_GROUP|      VIC_RACE|VIC_SEX|\n",
      "+----------+------------+-------------------+------------+------------+-----------+----------+-----+--------------------+-----+--------------------+----------------+-----------+---------+-----------------+-------------+----------------+-----------------+--------+----------+-----------+----------+----------+--------------+---------+--------+----------------+-----------------+------------------+--------------------+--------------------+------------+-------------+--------------+-------+\n",
      "| 211921838|  08/31/2019|2023-05-08 18:00:00|        null|        null|         71|09/05/2019|  341|       PETIT LARCENY|  321|LARCENY,PETIT FRO...|       COMPLETED|MISDEMEANOR| BROOKLYN|             null|       STREET|N.Y. POLICE DEPT|                0|    null|      null|       null|   1001797|    182700|          null|     null|    null|            null|40.66813685500005|-73.93674924299995|(40.6681368550000...|PATROL BORO BKLYN...|        null|        45-64|         BLACK|      F|\n",
      "| 751236093|  06/19/2013|2023-05-08 16:30:00|        null|        null|         40|06/19/2013|  118|   DANGEROUS WEAPONS|  793|WEAPONS POSSESSION 3|       COMPLETED|     FELONY|    BRONX|             null|       STREET|N.Y. POLICE DEPT|                0|      NA|      null|         NA|   1004972|    234409|          null|     null|    null|            null|      40.81005831|     -73.925144953|(40.81005831, -73...|   PATROL BORO BRONX|        null|         null|       UNKNOWN|      E|\n",
      "| 212455683|  08/27/2019|2023-05-08 06:00:00|  08/28/2019|    06:30:00|         45|08/28/2019|  341|       PETIT LARCENY|  321|LARCENY,PETIT FRO...|       COMPLETED|MISDEMEANOR|    BRONX|          REAR OF|       STREET|N.Y. POLICE DEPT|                0|    null|      null|       null|   1027350|    245455|          null|     null|    null|            null|40.84029557200005|-73.84423546299998|(40.8402955720000...|   PATROL BORO BRONX|        null|        25-44|WHITE HISPANIC|      F|\n",
      "| 635334663|  08/28/2019|2023-05-08 15:00:00|  08/29/2019|    00:05:00|        101|08/29/2019|  110|GRAND LARCENY OF ...|  441|LARCENY,GRAND OF ...|       COMPLETED|     FELONY|   QUEENS|             null|       STREET|N.Y. POLICE DEPT|                0|    null|      null|       null|   1052985|    157694|       UNKNOWN|  UNKNOWN|       U|            null|40.59925153100005|-73.75248562599995|(40.5992515310000...|PATROL BORO QUEEN...|        null|      UNKNOWN|       UNKNOWN|      D|\n",
      "| 812789888|  06/02/2015|2023-05-08 22:20:00|        null|        null|         13|06/02/2015|  109|       GRAND LARCENY|  443|LARCENY,GRAND OF ...|       COMPLETED|     FELONY|MANHATTAN|             null|       STREET|N.Y. POLICE DEPT|                0|    null|      null|         NA|    989164|    207429|          null|     null|    null|            null|     40.736028194|     -73.982269757|(40.736028194, -7...|PATROL BORO MAN S...|        null|         null|       UNKNOWN|      D|\n",
      "+----------+------------+-------------------+------------+------------+-----------+----------+-----+--------------------+-----+--------------------+----------------+-----------+---------+-----------------+-------------+----------------+-----------------+--------+----------+-----------+----------+----------+--------------+---------+--------+----------------+-----------------+------------------+--------------------+--------------------+------------+-------------+--------------+-------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-------+-------------------+------------+------------+------------+------------------+----------+------------------+--------------------+------------------+--------------------+----------------+----------+-------------+-----------------+------------------+----------------+------------------+--------------------+--------------------+------------------+------------------+------------------+------------------+--------------------+--------+-----------------+-------------------+-------------------+--------------------+--------------------+--------------+-----------------+--------------------+-------+\n",
      "|summary|         CMPLNT_NUM|CMPLNT_FR_DT|CMPLNT_TO_DT|CMPLNT_TO_TM|       ADDR_PCT_CD|    RPT_DT|             KY_CD|           OFNS_DESC|             PD_CD|             PD_DESC|CRM_ATPT_CPTD_CD|LAW_CAT_CD|      BORO_NM|LOC_OF_OCCUR_DESC|     PREM_TYP_DESC|      JURIS_DESC| JURISDICTION_CODE|            PARKS_NM|          HADEVELOPT|       HOUSING_PSA|        X_COORD_CD|        Y_COORD_CD|    SUSP_AGE_GROUP|           SUSP_RACE|SUSP_SEX| TRANSIT_DISTRICT|           Latitude|          Longitude|             Lat_Lon|         PATROL_BORO|  STATION_NAME|    VIC_AGE_GROUP|            VIC_RACE|VIC_SEX|\n",
      "+-------+-------------------+------------+------------+------------+------------------+----------+------------------+--------------------+------------------+--------------------+----------------+----------+-------------+-----------------+------------------+----------------+------------------+--------------------+--------------------+------------------+------------------+------------------+------------------+--------------------+--------+-----------------+-------------------+-------------------+--------------------+--------------------+--------------+-----------------+--------------------+-------+\n",
      "|  count|            1958512|     1958347|     1522902|     1524069|           1957951|   1958512|           1958512|             1953781|           1956813|             1956813|         1958473|   1958512|      1955411|          1553789|           1947974|         1958512|           1956813|             1038089|               87436|           1542869|           1954032|           1954032|            736026|             1078864| 1045572|            42960|            1954032|            1954032|             1954032|             1956700|         42960|          1548465|             1958431|1958447|\n",
      "|   mean|5.500681734125775E8|        null|        null|        null|63.348162441245975|      null| 296.8777985531873|                null| 412.7305041411724|                null|            null|      null|         null|             null|              null|            null|0.7139997536811131|                null|                null| 6245.155305023682|1004882.5818916988| 207111.1648939219|             464.1|                null|    null|13.53554469273743| 40.735105939272586| -73.92552104371444|                null|                null|          null|228.7927927927928|                null|   null|\n",
      "| stddev|2.596912175119076E8|        null|        null|        null| 34.50520432939566|      null|151.09440654529442|                null|217.57955918094126|                null|            null|      null|         null|             null|              null|            null| 6.680951294059437|                null|                null|13367.500163763392|21686.109229857488|30788.415922019147|1172.6431928029594|                null|    null|12.45881571596203|0.08449444940879369|0.07820813294561418|                null|                null|          null|777.2086430661171|                null|   null|\n",
      "|    min|          100000065|  01/01/1955|  01/01/1981|    00:00:00|                 1|01/01/2006|               101| ADMINISTRATIVE CODE|               100|A.B.C.,FALSE PROO...|       ATTEMPTED|    FELONY|        BRONX|         FRONT OF|ABANDONED BUILDING|         AMTRACK|                 0|\"\"\"UNCLE\"\" VITO E...|1162-1176 WASHING...|             1,193|            152021|            121131|                -1|AMERICAN INDIAN/A...|       F|                1|       40.498905363|      -76.995012742|(40.498905363, -7...|PATROL BORO BKLYN...|\"AVENUE \"\"H\"\"\"|               -1|AMERICAN INDIAN/A...|      D|\n",
      "|    max|          999999664|  12/31/2021|  12/31/2021|    24:00:00|               123|12/31/2021|               881|VEHICLE AND TRAFF...|               969| WOUNDS,REPORTING OF|       COMPLETED| VIOLATION|STATEN ISLAND|          REAR OF|       VIDEO STORE|U.S. PARK POLICE|                97|       ZION TRIANGLE|     WYCKOFF GARDENS|                NA|           1067298|           5205015|           UNKNOWN|      WHITE HISPANIC|       U|               34|       54.304231906|      -73.700315857|(54.304231906, -7...|PATROL BORO STATE...| ZEREGA AVENUE|          UNKNOWN|      WHITE HISPANIC|      U|\n",
      "+-------+-------------------+------------+------------+------------+------------------+----------+------------------+--------------------+------------------+--------------------+----------------+----------+-------------+-----------------+------------------+----------------+------------------+--------------------+--------------------+------------------+------------------+------------------+------------------+--------------------+--------+-----------------+-------------------+-------------------+--------------------+--------------------+--------------+-----------------+--------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display the schema of the dataframe\n",
    "df.printSchema()\n",
    "\n",
    "# Display the number of rows and columns in the dataframe\n",
    "print(\"Number of rows: \", df.count())\n",
    "print(\"Number of columns: \", len(df.columns))\n",
    "\n",
    "# Display the first 5 rows of the dataframe\n",
    "df.show(5)\n",
    "\n",
    "# Display summary statistics of the dataframe\n",
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f9fa853-844a-4d09-a54e-f4f69dfbdadf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+------------+-------------------+------------+------------+------------------+----------+------------------+--------------------+------------------+--------------------+----------------+----------+-------------+-----------------+------------------+----------------+------------------+--------------------+--------------------+------------------+------------------+------------------+------------------+--------------------+--------+-----------------+-------------------+-------------------+--------------------+--------------------+--------------+-----------------+--------------------+-------+\n",
      "|summary|         CMPLNT_NUM|CMPLNT_FR_DT|       CMPLNT_FR_TM|CMPLNT_TO_DT|CMPLNT_TO_TM|       ADDR_PCT_CD|    RPT_DT|             KY_CD|           OFNS_DESC|             PD_CD|             PD_DESC|CRM_ATPT_CPTD_CD|LAW_CAT_CD|      BORO_NM|LOC_OF_OCCUR_DESC|     PREM_TYP_DESC|      JURIS_DESC| JURISDICTION_CODE|            PARKS_NM|          HADEVELOPT|       HOUSING_PSA|        X_COORD_CD|        Y_COORD_CD|    SUSP_AGE_GROUP|           SUSP_RACE|SUSP_SEX| TRANSIT_DISTRICT|           Latitude|          Longitude|             Lat_Lon|         PATROL_BORO|  STATION_NAME|    VIC_AGE_GROUP|            VIC_RACE|VIC_SEX|\n",
      "+-------+-------------------+------------+-------------------+------------+------------+------------------+----------+------------------+--------------------+------------------+--------------------+----------------+----------+-------------+-----------------+------------------+----------------+------------------+--------------------+--------------------+------------------+------------------+------------------+------------------+--------------------+--------+-----------------+-------------------+-------------------+--------------------+--------------------+--------------+-----------------+--------------------+-------+\n",
      "|  count|            1958512|     1958347|            1958501|     1522902|     1524069|           1957951|   1958512|           1958512|             1953781|           1956813|             1956813|         1958473|   1958512|      1955411|          1553789|           1947974|         1958512|           1956813|             1038089|               87436|           1542869|           1954032|           1954032|            736026|             1078864| 1045572|            42960|            1954032|            1954032|             1954032|             1956700|         42960|          1548465|             1958431|1958447|\n",
      "|   mean|5.500681734125775E8|        null|               null|        null|        null|63.348162441245975|      null| 296.8777985531873|                null| 412.7305041411724|                null|            null|      null|         null|             null|              null|            null|0.7139997536811131|                null|                null| 6245.155305023682|1004882.5818916988| 207111.1648939219|             464.1|                null|    null|13.53554469273743| 40.735105939272586| -73.92552104371444|                null|                null|          null|228.7927927927928|                null|   null|\n",
      "| stddev|2.596912175119076E8|        null|               null|        null|        null| 34.50520432939566|      null|151.09440654529442|                null|217.57955918094126|                null|            null|      null|         null|             null|              null|            null| 6.680951294059437|                null|                null|13367.500163763392|21686.109229857488|30788.415922019147|1172.6431928029594|                null|    null|12.45881571596203|0.08449444940879369|0.07820813294561418|                null|                null|          null|777.2086430661171|                null|   null|\n",
      "|    min|          100000065|  01/01/1955|2023-05-08 00:00:00|  01/01/1981|    00:00:00|                 1|01/01/2006|               101| ADMINISTRATIVE CODE|               100|A.B.C.,FALSE PROO...|       ATTEMPTED|    FELONY|        BRONX|         FRONT OF|ABANDONED BUILDING|         AMTRACK|                 0|\"\"\"UNCLE\"\" VITO E...|1162-1176 WASHING...|             1,193|           1000001|            121131|                -1|AMERICAN INDIAN/A...|       F|                1|       40.498905363|      -73.700315857|(40.498905363, -7...|PATROL BORO BKLYN...|\"AVENUE \"\"H\"\"\"|               -1|AMERICAN INDIAN/A...|      D|\n",
      "|    max|          999999664|  12/31/2021|2023-05-08 23:59:00|  12/31/2021|    24:00:00|                94|12/31/2021|               881|VEHICLE AND TRAFF...|               969| WOUNDS,REPORTING OF|       COMPLETED| VIOLATION|STATEN ISLAND|          REAR OF|       VIDEO STORE|U.S. PARK POLICE|                97|       ZION TRIANGLE|     WYCKOFF GARDENS|                NA|            999999|           5205015|           UNKNOWN|      WHITE HISPANIC|       U|                4|       54.304231906|      -76.995012742|(54.304231906, -7...|PATROL BORO STATE...| ZEREGA AVENUE|          UNKNOWN|      WHITE HISPANIC|      U|\n",
      "+-------+-------------------+------------+-------------------+------------+------------+------------------+----------+------------------+--------------------+------------------+--------------------+----------------+----------+-------------+-----------------+------------------+----------------+------------------+--------------------+--------------------+------------------+------------------+------------------+------------------+--------------------+--------+-----------------+-------------------+-------------------+--------------------+--------------------+--------------+-----------------+--------------------+-------+\n",
      "\n",
      "+-------+-------------------+------------+------------+------------+------------------+----------+------------------+--------------------+------------------+--------------------+----------------+----------+-------------+-----------------+------------------+----------------+------------------+--------------------+--------------------+------------------+------------------+------------------+------------------+--------------------+--------+-----------------+-------------------+-------------------+--------------------+--------------------+--------------+-----------------+--------------------+-------+\n",
      "|summary|         CMPLNT_NUM|CMPLNT_FR_DT|CMPLNT_TO_DT|CMPLNT_TO_TM|       ADDR_PCT_CD|    RPT_DT|             KY_CD|           OFNS_DESC|             PD_CD|             PD_DESC|CRM_ATPT_CPTD_CD|LAW_CAT_CD|      BORO_NM|LOC_OF_OCCUR_DESC|     PREM_TYP_DESC|      JURIS_DESC| JURISDICTION_CODE|            PARKS_NM|          HADEVELOPT|       HOUSING_PSA|        X_COORD_CD|        Y_COORD_CD|    SUSP_AGE_GROUP|           SUSP_RACE|SUSP_SEX| TRANSIT_DISTRICT|           Latitude|          Longitude|             Lat_Lon|         PATROL_BORO|  STATION_NAME|    VIC_AGE_GROUP|            VIC_RACE|VIC_SEX|\n",
      "+-------+-------------------+------------+------------+------------+------------------+----------+------------------+--------------------+------------------+--------------------+----------------+----------+-------------+-----------------+------------------+----------------+------------------+--------------------+--------------------+------------------+------------------+------------------+------------------+--------------------+--------+-----------------+-------------------+-------------------+--------------------+--------------------+--------------+-----------------+--------------------+-------+\n",
      "|  count|            1958512|     1958347|     1522902|     1524069|           1957951|   1958512|           1958512|             1953781|           1956813|             1956813|         1958473|   1958512|      1955411|          1553789|           1947974|         1958512|           1956813|             1038089|               87436|           1542869|           1954032|           1954032|            736026|             1078864| 1045572|            42960|            1954032|            1954032|             1954032|             1956700|         42960|          1548465|             1958431|1958447|\n",
      "|   mean|5.500681734125775E8|        null|        null|        null|63.348162441245975|      null| 296.8777985531873|                null| 412.7305041411724|                null|            null|      null|         null|             null|              null|            null|0.7139997536811131|                null|                null| 6245.155305023682|1004882.5818916988| 207111.1648939219|             464.1|                null|    null|13.53554469273743| 40.735105939272586| -73.92552104371444|                null|                null|          null|228.7927927927928|                null|   null|\n",
      "| stddev|2.596912175119076E8|        null|        null|        null| 34.50520432939566|      null|151.09440654529442|                null|217.57955918094126|                null|            null|      null|         null|             null|              null|            null| 6.680951294059437|                null|                null|13367.500163763392|21686.109229857488|30788.415922019147|1172.6431928029594|                null|    null|12.45881571596203|0.08449444940879369|0.07820813294561418|                null|                null|          null|777.2086430661171|                null|   null|\n",
      "|    min|          100000065|  01/01/1955|  01/01/1981|    00:00:00|                 1|01/01/2006|               101| ADMINISTRATIVE CODE|               100|A.B.C.,FALSE PROO...|       ATTEMPTED|    FELONY|        BRONX|         FRONT OF|ABANDONED BUILDING|         AMTRACK|                 0|\"\"\"UNCLE\"\" VITO E...|1162-1176 WASHING...|             1,193|            152021|            121131|                -1|AMERICAN INDIAN/A...|       F|                1|       40.498905363|      -76.995012742|(40.498905363, -7...|PATROL BORO BKLYN...|\"AVENUE \"\"H\"\"\"|               -1|AMERICAN INDIAN/A...|      D|\n",
      "|    25%|          325243600|        null|        null|        null|                40|      null|               117|                null|               254|                null|            null|      null|         null|             null|              null|            null|                 0|                null|                null|             477.0|            991788|            184415|            -965.0|                null|    null|                3|       40.672786795|      -73.972819638|                null|                null|          null|            -85.0|                null|   null|\n",
      "|    50%|          550077760|        null|        null|        null|                63|      null|               341|                null|               380|                null|            null|      null|         null|             null|              null|            null|                 0|                null|                null|             696.0|           1004396|            206077|             928.0|                null|    null|               11| 40.732262379000076|      -73.927269471|                null|                null|          null|            507.0|                null|   null|\n",
      "|    75%|          774715147|        null|        null|        null|                94|      null|               351|                null|               637|                null|            null|      null|         null|             null|              null|            null|                 0|                null|                null|            1193.0|           1016702|            235143|            1018.0|                null|    null|               30|        40.81206043|      -73.882829229|                null|                null|          null|            938.0|                null|   null|\n",
      "|    max|          999999664|  12/31/2021|  12/31/2021|    24:00:00|               123|12/31/2021|               881|VEHICLE AND TRAFF...|               969| WOUNDS,REPORTING OF|       COMPLETED| VIOLATION|STATEN ISLAND|          REAR OF|       VIDEO STORE|U.S. PARK POLICE|                97|       ZION TRIANGLE|     WYCKOFF GARDENS|                NA|           1067298|           5205015|           UNKNOWN|      WHITE HISPANIC|       U|               34|       54.304231906|      -73.700315857|(54.304231906, -7...|PATROL BORO STATE...| ZEREGA AVENUE|          UNKNOWN|      WHITE HISPANIC|      U|\n",
      "+-------+-------------------+------------+------------+------------+------------------+----------+------------------+--------------------+------------------+--------------------+----------------+----------+-------------+-----------------+------------------+----------------+------------------+--------------------+--------------------+------------------+------------------+------------------+------------------+--------------------+--------+-----------------+-------------------+-------------------+--------------------+--------------------+--------------+-----------------+--------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Generate column-level statistics using Spark DataFrame API\n",
    "col_stats = df.select([col(c).cast(\"string\") for c in df.columns]).describe()\n",
    "\n",
    "# Display column-level statistics\n",
    "col_stats.show()\n",
    "\n",
    "# Generate row-level statistics using Spark DataFrame API\n",
    "row_stats = df.summary()\n",
    "\n",
    "# Display row-level statistics\n",
    "row_stats.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c278b0db-5e10-4381-90ac-7384c835aba4",
   "metadata": {},
   "source": [
    "## Cleaning, Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b6291a7-b178-4387-b9a0-ef027ba40892",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------+-------------+-------------------+------------------+------------------+------------------------+------------------+-------------------+-------------------------+---------------------+------------------+-------------------------+-----------------+------------------+-------------------+-------------------+-------------------+----------------------+-----------------+-----------------+------------------------+-------------------+-------------------+-------------------+-------------------+--------------------+---------------------+--------------------+--------------------+---------------------------+\n",
      "|CMPLNT_NUM_percent|CMPLNT_FR_DT_percent|CMPLNT_FR_TM_percent|CMPLNT_TO_DT_percent|CMPLNT_TO_TM_percent| ADDR_PCT_CD_percent|RPT_DT_percent|KY_CD_percent|  OFNS_DESC_percent|     PD_CD_percent|   PD_DESC_percent|CRM_ATPT_CPTD_CD_percent|LAW_CAT_CD_percent|    BORO_NM_percent|LOC_OF_OCCUR_DESC_percent|PREM_TYP_DESC_percent|JURIS_DESC_percent|JURISDICTION_CODE_percent| PARKS_NM_percent|HADEVELOPT_percent|HOUSING_PSA_percent| X_COORD_CD_percent| Y_COORD_CD_percent|SUSP_AGE_GROUP_percent|SUSP_RACE_percent| SUSP_SEX_percent|TRANSIT_DISTRICT_percent|   Latitude_percent|  Longitude_percent|    Lat_Lon_percent|PATROL_BORO_percent|STATION_NAME_percent|VIC_AGE_GROUP_percent|    VIC_RACE_percent|     VIC_SEX_percent|CMPLNT_FR_TM_double_percent|\n",
      "+------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------+-------------+-------------------+------------------+------------------+------------------------+------------------+-------------------+-------------------------+---------------------+------------------+-------------------------+-----------------+------------------+-------------------+-------------------+-------------------+----------------------+-----------------+-----------------+------------------------+-------------------+-------------------+-------------------+-------------------+--------------------+---------------------+--------------------+--------------------+---------------------------+\n",
      "|               0.0|0.008424763289681145| 5.61650885978743E-4|   22.24188567647275|  22.182299623387554|0.028644195184915896|           0.0|          0.0|0.24156094014231214|0.0867495322979895|0.0867495322979895|    0.001991307686651907|               0.0|0.15833449067455294|        20.66482104781589|   0.5380615487676359|               0.0|       0.0867495322979895|46.99603576592842| 95.53559028486933| 21.222387200078426|0.22874508810770627|0.22874508810770627|     62.41912227241906|44.91409804994812|46.61395998594852|       97.80649799439574|0.22874508810770627|0.22874508810770627|0.22874508810770627|0.09251921867213476|   97.80649799439574|   20.936660076629604|0.004135792887661...|0.003318846144419...|        5.61650885978743E-4|\n",
      "+------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------+-------------+-------------------+------------------+------------------+------------------------+------------------+-------------------+-------------------------+---------------------+------------------+-------------------------+-----------------+------------------+-------------------+-------------------+-------------------+----------------------+-----------------+-----------------+------------------------+-------------------+-------------------+-------------------+-------------------+--------------------+---------------------+--------------------+--------------------+---------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check each col for percent missing value\n",
    "from pyspark.sql.functions import count, when, col\n",
    "\n",
    "# Convert the timestamp column to double\n",
    "df = df.withColumn(\"CMPLNT_FR_TM_double\", df[\"CMPLNT_FR_TM\"].cast(\"double\"))\n",
    "\n",
    "# Calculate the count of missing values for each column\n",
    "missing_values_count = df.select([count(when(col(c).isNull(), c)).alias(c) for c in df.columns])\n",
    "\n",
    "# Calculate the percentage of missing values for each column\n",
    "missing_values_percent = missing_values_count.select([(col(c) / df.count() * 100).alias(c + '_percent') for c in df.columns])\n",
    "\n",
    "# Show the result\n",
    "missing_values_percent.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fd4566d9-afa0-47df-807a-3a0f1e5675dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dropping rows with null values in selected columns\n",
    "df = df.na.drop(subset=['Y_COORD_CD', 'X_COORD_CD', 'Latitude', 'Longitude', 'CRM_ATPT_CPTD_CD', 'CMPLNT_FR_TM', 'Lat_Lon', 'CMPLNT_FR_DT', 'BORO_NM', 'OFNS_DESC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bcf4af32-8da2-4d23-89f0-e29db3a387e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dropping columns that are not significant for future data exploration\n",
    "df = df.drop('PARKS_NM', 'STATION_NAME', 'TRANSIT_DISTRICT', 'HADEVELOPT', 'HOUSING_PSA', 'CMPLNT_TO_DT', 'CMPLNT_TO_TM')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8b34f4d8-0244-4aec-9799-d6b6fcb432dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# replacing null values in 'LOC_OF_OCCUR_DESC' with 'UNKNOWN'\n",
    "df = df.fillna({'LOC_OF_OCCUR_DESC':'UNKNOWN'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0ae8d7ad-c9a4-42ca-a523-d9fe0d441b48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# replacing null values in 'VIC_RACE' with 'UNKNOWN'\n",
    "df = df.fillna({'VIC_RACE':'UNKNOWN'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a3afbba8-a5ee-4a3f-889b-996f05ef5134",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# replacing null values in 'VIC_AGE_GROUP' with 'UNKNOWN'\n",
    "df = df.fillna({'VIC_AGE_GROUP':'UNKNOWN'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d4ad21ca-7618-48fa-b9b7-847a595df27c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# replacing null values in 'VIC_SEX' with 'UNKNOWN'\n",
    "df = df.fillna({'VIC_SEX':'UNKNOWN'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b84c50bd-5dae-40bb-8bc8-c51643c7ace4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------------+--------------------+-------------------+--------------+-------------+-----------------+-------------+---------------+------------------------+------------------+---------------+-------------------------+---------------------+------------------+-------------------------+------------------+------------------+----------------------+------------------+-----------------+----------------+-----------------+---------------+--------------------+---------------------+----------------+---------------+---------------------------+\n",
      "|CMPLNT_NUM_percent|CMPLNT_FR_DT_percent|CMPLNT_FR_TM_percent|ADDR_PCT_CD_percent|RPT_DT_percent|KY_CD_percent|OFNS_DESC_percent|PD_CD_percent|PD_DESC_percent|CRM_ATPT_CPTD_CD_percent|LAW_CAT_CD_percent|BORO_NM_percent|LOC_OF_OCCUR_DESC_percent|PREM_TYP_DESC_percent|JURIS_DESC_percent|JURISDICTION_CODE_percent|X_COORD_CD_percent|Y_COORD_CD_percent|SUSP_AGE_GROUP_percent| SUSP_RACE_percent| SUSP_SEX_percent|Latitude_percent|Longitude_percent|Lat_Lon_percent| PATROL_BORO_percent|VIC_AGE_GROUP_percent|VIC_RACE_percent|VIC_SEX_percent|CMPLNT_FR_TM_double_percent|\n",
      "+------------------+--------------------+--------------------+-------------------+--------------+-------------+-----------------+-------------+---------------+------------------------+------------------+---------------+-------------------------+---------------------+------------------+-------------------------+------------------+------------------+----------------------+------------------+-----------------+----------------+-----------------+---------------+--------------------+---------------------+----------------+---------------+---------------------------+\n",
      "|               0.0|                 0.0|                 0.0|                0.0|           0.0|          0.0|              0.0|          0.0|            0.0|                     0.0|               0.0|            0.0|                      0.0|  0.44359216651071826|               0.0|                      0.0|               0.0|               0.0|     62.32241283719658|44.825571626544004|46.51849773682185|             0.0|              0.0|            0.0|0.001130432950681...|                  0.0|             0.0|            0.0|                        0.0|\n",
      "+------------------+--------------------+--------------------+-------------------+--------------+-------------+-----------------+-------------+---------------+------------------------+------------------+---------------+-------------------------+---------------------+------------------+-------------------------+------------------+------------------+----------------------+------------------+-----------------+----------------+-----------------+---------------+--------------------+---------------------+----------------+---------------+---------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check each col for percent missing value\n",
    "from pyspark.sql.functions import count, when, col\n",
    "\n",
    "# Convert the timestamp column to double\n",
    "df = df.withColumn(\"CMPLNT_FR_TM_double\", df[\"CMPLNT_FR_TM\"].cast(\"double\"))\n",
    "\n",
    "# Calculate the count of missing values for each column\n",
    "missing_values_count = df.select([count(when(col(c).isNull(), c)).alias(c) for c in df.columns])\n",
    "\n",
    "# Calculate the percentage of missing values for each column\n",
    "missing_values_percent = missing_values_count.select([(col(c) / df.count() * 100).alias(c + '_percent') for c in df.columns])\n",
    "\n",
    "# Show the result\n",
    "missing_values_percent.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2fc5e47f-11fa-42fe-b005-fb6a4de3abb7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean dataset: \n",
      "Observations:  1946157\n",
      "Variables:  28\n",
      "+----------+------------+-------------------+-----------+----------+-----+--------------------+-----+--------------------+----------------+-----------+---------+-----------------+-------------+----------------+-----------------+----------+----------+--------------+---------+--------+-----------------+------------------+--------------------+--------------------+-------------+--------------+-------+\n",
      "|CMPLNT_NUM|CMPLNT_FR_DT|       CMPLNT_FR_TM|ADDR_PCT_CD|    RPT_DT|KY_CD|           OFNS_DESC|PD_CD|             PD_DESC|CRM_ATPT_CPTD_CD| LAW_CAT_CD|  BORO_NM|LOC_OF_OCCUR_DESC|PREM_TYP_DESC|      JURIS_DESC|JURISDICTION_CODE|X_COORD_CD|Y_COORD_CD|SUSP_AGE_GROUP|SUSP_RACE|SUSP_SEX|         Latitude|         Longitude|             Lat_Lon|         PATROL_BORO|VIC_AGE_GROUP|      VIC_RACE|VIC_SEX|\n",
      "+----------+------------+-------------------+-----------+----------+-----+--------------------+-----+--------------------+----------------+-----------+---------+-----------------+-------------+----------------+-----------------+----------+----------+--------------+---------+--------+-----------------+------------------+--------------------+--------------------+-------------+--------------+-------+\n",
      "| 211921838|  08/31/2019|2023-05-08 18:00:00|         71|09/05/2019|  341|       PETIT LARCENY|  321|LARCENY,PETIT FRO...|       COMPLETED|MISDEMEANOR| BROOKLYN|          UNKNOWN|       STREET|N.Y. POLICE DEPT|                0|   1001797|    182700|          null|     null|    null|40.66813685500005|-73.93674924299995|(40.6681368550000...|PATROL BORO BKLYN...|        45-64|         BLACK|      F|\n",
      "| 751236093|  06/19/2013|2023-05-08 16:30:00|         40|06/19/2013|  118|   DANGEROUS WEAPONS|  793|WEAPONS POSSESSION 3|       COMPLETED|     FELONY|    BRONX|          UNKNOWN|       STREET|N.Y. POLICE DEPT|                0|   1004972|    234409|          null|     null|    null|      40.81005831|     -73.925144953|(40.81005831, -73...|   PATROL BORO BRONX|      UNKNOWN|       UNKNOWN|      E|\n",
      "| 212455683|  08/27/2019|2023-05-08 06:00:00|         45|08/28/2019|  341|       PETIT LARCENY|  321|LARCENY,PETIT FRO...|       COMPLETED|MISDEMEANOR|    BRONX|          REAR OF|       STREET|N.Y. POLICE DEPT|                0|   1027350|    245455|          null|     null|    null|40.84029557200005|-73.84423546299998|(40.8402955720000...|   PATROL BORO BRONX|        25-44|WHITE HISPANIC|      F|\n",
      "| 635334663|  08/28/2019|2023-05-08 15:00:00|        101|08/29/2019|  110|GRAND LARCENY OF ...|  441|LARCENY,GRAND OF ...|       COMPLETED|     FELONY|   QUEENS|          UNKNOWN|       STREET|N.Y. POLICE DEPT|                0|   1052985|    157694|       UNKNOWN|  UNKNOWN|       U|40.59925153100005|-73.75248562599995|(40.5992515310000...|PATROL BORO QUEEN...|      UNKNOWN|       UNKNOWN|      D|\n",
      "| 812789888|  06/02/2015|2023-05-08 22:20:00|         13|06/02/2015|  109|       GRAND LARCENY|  443|LARCENY,GRAND OF ...|       COMPLETED|     FELONY|MANHATTAN|          UNKNOWN|       STREET|N.Y. POLICE DEPT|                0|    989164|    207429|          null|     null|    null|     40.736028194|     -73.982269757|(40.736028194, -7...|PATROL BORO MAN S...|      UNKNOWN|       UNKNOWN|      D|\n",
      "+----------+------------+-------------------+-----------+----------+-----+--------------------+-----+--------------------+----------------+-----------+---------+-----------------+-------------+----------------+-----------------+----------+----------+--------------+---------+--------+-----------------+------------------+--------------------+--------------------+-------------+--------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show the cleaned data till now\n",
    "print('Clean dataset: ')\n",
    "print(\"Observations: \", df.count())\n",
    "print(\"Variables: \", len(df.columns))\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "43e78392-b48e-4df9-8e68-6171ab512595",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.fillna('UNKNOWN')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b7230ff-bcc4-4357-9919-5bf707bb136d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|CMPLNT_FR_DT|count|\n",
      "+------------+-----+\n",
      "|  01/01/2010|  633|\n",
      "|  01/01/2016|  599|\n",
      "|  01/01/2011|  597|\n",
      "|  01/01/2014|  596|\n",
      "|  01/01/2008|  582|\n",
      "|  01/01/2007|  574|\n",
      "|  01/01/2017|  554|\n",
      "|  01/01/2019|  542|\n",
      "|  01/01/2012|  532|\n",
      "|  01/01/2013|  522|\n",
      "+------------+-----+\n",
      "only showing top 10 rows\n",
      "\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "+----------+-----+\n",
      "|    RPT_DT|count|\n",
      "+----------+-----+\n",
      "|11/01/2006|  489|\n",
      "|05/29/2007|  487|\n",
      "|06/05/2007|  483|\n",
      "|06/06/2007|  468|\n",
      "|09/17/2009|  465|\n",
      "|06/21/2006|  458|\n",
      "|08/16/2006|  458|\n",
      "|07/23/2008|  456|\n",
      "|10/04/2006|  456|\n",
      "|10/23/2007|  456|\n",
      "+----------+-----+\n",
      "only showing top 10 rows\n",
      "\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "+--------------------+------+\n",
      "|           OFNS_DESC| count|\n",
      "+--------------------+------+\n",
      "|       PETIT LARCENY|332434|\n",
      "|       HARRASSMENT 2|254535|\n",
      "|ASSAULT 3 & RELAT...|204862|\n",
      "|CRIMINAL MISCHIEF...|197422|\n",
      "|       GRAND LARCENY|169426|\n",
      "|     DANGEROUS DRUGS|108730|\n",
      "|OFF. AGNST PUB OR...| 99817|\n",
      "|      FELONY ASSAULT| 77043|\n",
      "|             ROBBERY| 70369|\n",
      "|            BURGLARY| 66432|\n",
      "+--------------------+------+\n",
      "only showing top 10 rows\n",
      "\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "+--------------------+------+\n",
      "|             PD_DESC| count|\n",
      "+--------------------+------+\n",
      "|           ASSAULT 3|168513|\n",
      "|HARASSMENT,SUBD 3...|166889|\n",
      "|LARCENY,PETIT FRO...|100945|\n",
      "|AGGRAVATED HARASS...| 97233|\n",
      "|HARASSMENT,SUBD 1...| 87646|\n",
      "|LARCENY,PETIT FRO...| 76504|\n",
      "|MISCHIEF, CRIMINA...| 67412|\n",
      "|ASSAULT 2,1,UNCLA...| 62186|\n",
      "|LARCENY,PETIT FRO...| 61673|\n",
      "|CRIMINAL MISCHIEF...| 55329|\n",
      "+--------------------+------+\n",
      "only showing top 10 rows\n",
      "\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "+----------------+-------+\n",
      "|CRM_ATPT_CPTD_CD|  count|\n",
      "+----------------+-------+\n",
      "|       COMPLETED|1913348|\n",
      "|       ATTEMPTED|  32809|\n",
      "+----------------+-------+\n",
      "\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "+-----------+-------+\n",
      "| LAW_CAT_CD|  count|\n",
      "+-----------+-------+\n",
      "|MISDEMEANOR|1085115|\n",
      "|     FELONY| 602685|\n",
      "|  VIOLATION| 258357|\n",
      "+-----------+-------+\n",
      "\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "+-------------+------+\n",
      "|      BORO_NM| count|\n",
      "+-------------+------+\n",
      "|     BROOKLYN|576906|\n",
      "|    MANHATTAN|468624|\n",
      "|        BRONX|421387|\n",
      "|       QUEENS|389186|\n",
      "|STATEN ISLAND| 90054|\n",
      "+-------------+------+\n",
      "\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "+-----------------+------+\n",
      "|LOC_OF_OCCUR_DESC| count|\n",
      "+-----------------+------+\n",
      "|           INSIDE|991686|\n",
      "|         FRONT OF|460092|\n",
      "|          UNKNOWN|401589|\n",
      "|      OPPOSITE OF| 51385|\n",
      "|          REAR OF| 41405|\n",
      "+-----------------+------+\n",
      "\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "+--------------------+------+\n",
      "|       PREM_TYP_DESC| count|\n",
      "+--------------------+------+\n",
      "|              STREET|618448|\n",
      "|RESIDENCE - APT. ...|415849|\n",
      "|     RESIDENCE-HOUSE|192231|\n",
      "|RESIDENCE - PUBLI...|146468|\n",
      "|               OTHER| 51261|\n",
      "| COMMERCIAL BUILDING| 49877|\n",
      "|         CHAIN STORE| 47096|\n",
      "|TRANSIT - NYC SUBWAY| 41456|\n",
      "|    DEPARTMENT STORE| 39137|\n",
      "|      GROCERY/BODEGA| 25036|\n",
      "+--------------------+------+\n",
      "only showing top 10 rows\n",
      "\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "+-------------------+-------+\n",
      "|         JURIS_DESC|  count|\n",
      "+-------------------+-------+\n",
      "|   N.Y. POLICE DEPT|1731450|\n",
      "|N.Y. HOUSING POLICE| 148450|\n",
      "|N.Y. TRANSIT POLICE|  42276|\n",
      "|     PORT AUTHORITY|   8836|\n",
      "|              OTHER|   6297|\n",
      "|DEPT OF CORRECTIONS|   2456|\n",
      "|    POLICE DEPT NYC|   2187|\n",
      "|TRI-BORO BRDG TUNNL|   1462|\n",
      "| HEALTH & HOSP CORP|    981|\n",
      "|  N.Y. STATE POLICE|    484|\n",
      "+-------------------+-------+\n",
      "only showing top 10 rows\n",
      "\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "+--------------+-------+\n",
      "|SUSP_AGE_GROUP|  count|\n",
      "+--------------+-------+\n",
      "|       UNKNOWN|1424328|\n",
      "|         25-44| 280922|\n",
      "|         18-24| 103657|\n",
      "|         45-64|  99579|\n",
      "|           <18|  28971|\n",
      "|           65+|   8642|\n",
      "|          1017|      3|\n",
      "|          2020|      3|\n",
      "|          2018|      3|\n",
      "|          -960|      2|\n",
      "+--------------+-------+\n",
      "only showing top 10 rows\n",
      "\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "+--------------------+-------+\n",
      "|           SUSP_RACE|  count|\n",
      "+--------------------+-------+\n",
      "|             UNKNOWN|1158056|\n",
      "|               BLACK| 399497|\n",
      "|      WHITE HISPANIC| 180055|\n",
      "|               WHITE| 115619|\n",
      "|      BLACK HISPANIC|  55190|\n",
      "|ASIAN / PACIFIC I...|  34572|\n",
      "|AMERICAN INDIAN/A...|   3166|\n",
      "|               OTHER|      2|\n",
      "+--------------------+-------+\n",
      "\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "+--------+------+\n",
      "|SUSP_SEX| count|\n",
      "+--------+------+\n",
      "| UNKNOWN|905323|\n",
      "|       M|648527|\n",
      "|       F|202481|\n",
      "|       U|189826|\n",
      "+--------+------+\n",
      "\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "+--------------------+-----+\n",
      "|             Lat_Lon|count|\n",
      "+--------------------+-----+\n",
      "|(40.750430768, -7...| 5204|\n",
      "|(40.679700408, -7...| 3864|\n",
      "|(40.791151867, -7...| 2141|\n",
      "|(40.837323511, -7...| 1757|\n",
      "|(40.710093847, -7...| 1637|\n",
      "|(40.869058532, -7...| 1617|\n",
      "|(40.733926841, -7...| 1614|\n",
      "|(40.804384046, -7...| 1407|\n",
      "|(40.756266207, -7...| 1405|\n",
      "|(40.651700904, -7...| 1404|\n",
      "+--------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "+--------------------+------+\n",
      "|         PATROL_BORO| count|\n",
      "+--------------------+------+\n",
      "|   PATROL BORO BRONX|421336|\n",
      "|PATROL BORO BKLYN...|289722|\n",
      "|PATROL BORO BKLYN...|287208|\n",
      "|PATROL BORO MAN S...|235151|\n",
      "|PATROL BORO MAN N...|232944|\n",
      "|PATROL BORO QUEEN...|201867|\n",
      "|PATROL BORO QUEEN...|187878|\n",
      "|PATROL BORO STATE...| 90029|\n",
      "|             UNKNOWN|    22|\n",
      "+--------------------+------+\n",
      "\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "+-------------+------+\n",
      "|VIC_AGE_GROUP| count|\n",
      "+-------------+------+\n",
      "|        25-44|646609|\n",
      "|      UNKNOWN|606716|\n",
      "|        45-64|338375|\n",
      "|        18-24|196155|\n",
      "|          <18| 88090|\n",
      "|          65+| 70101|\n",
      "|          929|     4|\n",
      "|         -943|     3|\n",
      "|          946|     3|\n",
      "|          943|     3|\n",
      "+-------------+------+\n",
      "only showing top 10 rows\n",
      "\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "+--------------------+------+\n",
      "|            VIC_RACE| count|\n",
      "+--------------------+------+\n",
      "|             UNKNOWN|636190|\n",
      "|               BLACK|470018|\n",
      "|               WHITE|332923|\n",
      "|      WHITE HISPANIC|316066|\n",
      "|ASIAN / PACIFIC I...|115400|\n",
      "|      BLACK HISPANIC| 66872|\n",
      "|AMERICAN INDIAN/A...|  8680|\n",
      "|               OTHER|     8|\n",
      "+--------------------+------+\n",
      "\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "+-------+------+\n",
      "|VIC_SEX| count|\n",
      "+-------+------+\n",
      "|      F|763836|\n",
      "|      M|644400|\n",
      "|      E|294017|\n",
      "|      D|243843|\n",
      "|UNKNOWN|    61|\n",
      "+-------+------+\n",
      "\n",
      "\n",
      "------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StringType\n",
    "\n",
    "# Loop through all columns in the DataFrame\n",
    "for column in df.columns:\n",
    "    # Check if the column type is string\n",
    "    if isinstance(df.schema[column].dataType, StringType):\n",
    "        # Group by the column and count the occurrences, then show the top 10 results\n",
    "        df.groupBy(column).count().orderBy(col('count').desc()).show(10)\n",
    "        print('\\n------------------------------------------\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "00471221-0a66-4804-8d9a-2cb282257c45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when, col\n",
    "\n",
    "# modify abbreviations in VIC_SEX and SUSP_SEX columns\n",
    "df = df.withColumn('VIC_SEX', when(col('VIC_SEX') == 'U', 'UNKNOWN')\n",
    "                          .when(col('VIC_SEX') == 'E', 'UNKNOWN')\n",
    "                          .when(col('VIC_SEX') == 'D', 'BUSINESS/ORGANIZATION')\n",
    "                          .when(col('VIC_SEX') == 'F', 'FEMALE')\n",
    "                          .when(col('VIC_SEX') == 'M', 'MALE')\n",
    "                          .otherwise(col('VIC_SEX')))\n",
    "df = df.withColumn('SUSP_SEX', when(col('SUSP_SEX') == 'U', 'UNKNOWN')\n",
    "                            .when(col('SUSP_SEX') == 'E', 'UNKNOWN')\n",
    "                            .when(col('SUSP_SEX') == 'D', 'BUSINESS/ORGANIZATION')\n",
    "                            .when(col('SUSP_SEX') == 'F', 'FEMALE')\n",
    "                            .when(col('SUSP_SEX') == 'M', 'MALE')\n",
    "                            .otherwise(col('SUSP_SEX')))\n",
    "\n",
    "# remove erroneous age groups\n",
    "age_categories = ['<18', '18-24', '25-44', '45-64', '65+', 'UNKNOWN']\n",
    "df = df.filter(col('VIC_AGE_GROUP').isin(age_categories) & col('SUSP_AGE_GROUP').isin(age_categories))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "153e4707-881b-4f95-9b94-99d653983bee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when, col\n",
    "\n",
    "# Fill in missing values in the OFNS_DESC column with \"OTHER\"\n",
    "df = df.withColumn('OFNS_DESC', when(col('OFNS_DESC').isNull(), 'OTHER')\n",
    "                                .otherwise(col('OFNS_DESC')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d4e5b35-6c8a-4cd0-be09-9ee145333ae2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|           OFNS_DESC| count|\n",
      "+--------------------+------+\n",
      "|OTHER TRAFFIC INF...|     4|\n",
      "|ANTICIPATORY OFFE...|    34|\n",
      "|   FELONY SEX CRIMES|     8|\n",
      "|OTHER OFFENSES RE...|  4234|\n",
      "|VEHICLE AND TRAFF...| 24955|\n",
      "|KIDNAPPING & RELA...|   760|\n",
      "|OFF. AGNST PUB OR...| 99801|\n",
      "|PETIT LARCENY OF ...|   370|\n",
      "|      FELONY ASSAULT| 77033|\n",
      "|OFFENSES RELATED ...|   425|\n",
      "|ALCOHOLIC BEVERAG...|   359|\n",
      "|CRIMINAL MISCHIEF...|197409|\n",
      "|         THEFT-FRAUD| 20064|\n",
      "|   THEFT OF SERVICES|  1220|\n",
      "|            JOSTLING|   109|\n",
      "|MISCELLANEOUS PEN...| 49907|\n",
      "|LOITERING/GAMBLIN...|    60|\n",
      "|               ARSON|  4561|\n",
      "|OFFENSES AGAINST ...|  4940|\n",
      "|            GAMBLING|   797|\n",
      "+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import count\n",
    "\n",
    "df.groupBy('OFNS_DESC').agg(count('*').alias('count')).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4935161d-4ca9-4d67-8b17-d481f8984321",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when\n",
    "\n",
    "# categorize property related offenses\n",
    "prop = ['BURGLARY', 'PETIT LARCENY', 'GRAND LARCENY', 'ROBBERY', 'THEFT-FRAUD', \n",
    "        'GRAND LARCENY OF MOTOR VEHICLE', 'FORGERY', 'JOSTLING', 'ARSON',\n",
    "        'PETIT LARCENY OF MOTOR VEHICLE', 'OTHER OFFENSES RELATED TO THEF',\n",
    "        \"BURGLAR'S TOOLS\", 'FRAUDS', 'POSSESSION OF STOLEN PROPERTY',\n",
    "        'CRIMINAL MISCHIEF & RELATED OF', 'OFFENSES INVOLVING FRAUD',\n",
    "        'FRAUDULENT ACCOSTING', 'THEFT OF SERVICES']\n",
    "\n",
    "# categorize sexual offenses\n",
    "sexual = ['SEX CRIMES', 'HARRASSMENT 2', 'RAPE', 'PROSTITUTION & RELATED OFFENSES',\n",
    "          'FELONY SEX CRIMES', 'LOITERING/DEVIATE SEX']\n",
    "\n",
    "# categorize drugs/alcohol related offenses\n",
    "drug_alch = ['DANGEROUS DRUGS', 'INTOXICATED & IMPAIRED DRIVING',\n",
    "             'ALCOHOLIC BEVERAGE CONTROL LAW', 'INTOXICATED/IMPAIRED DRIVING',\n",
    "             'UNDER THE INFLUENCE OF DRUGS', 'LOITERING FOR DRUG PURPOSES']\n",
    "\n",
    "# categorize personal (assault/homicidal/kidnapping/weapon) offenses\n",
    "personal = ['ASSAULT 3 & RELATED OFFENSES', 'FELONY ASSAULT',\n",
    "            'OFFENSES AGAINST THE PERSON', 'HOMICIDE-NEGLIGENT,UNCLASSIFIE',\n",
    "            'HOMICIDE-NEGLIGENT-VEHICLE', 'KIDNAPPING & RELATED OFFENSES',\n",
    "            'ENDAN WELFARE INCOMP', 'OFFENSES RELATED TO CHILDREN',\n",
    "            'CHILD ABANDONMENT/NON SUPPORT', 'KIDNAPPING', 'DANGEROUS WEAPONS',\n",
    "            'UNLAWFUL POSS. WEAP. ON SCHOOL']\n",
    "\n",
    "# categorize administrative/trespassing/loitering/traffic offenses\n",
    "admin = ['OFF. AGNST PUB ORD SENSBLTY &', 'CRIMINAL TRESPASS', \n",
    "         'VEHICLE AND TRAFFIC LAWS', 'OFFENSES AGAINST PUBLIC ADMINI',\n",
    "         'ADMINISTRATIVE CODE', 'OFFENSES AGAINST PUBLIC SAFETY',\n",
    "         'LOITERING/GAMBLING (CARDS, DIC', 'DISORDERLY CONDUCT',\n",
    "         'NEW YORK CITY HEALTH CODE', 'DISRUPTION OF A RELIGIOUS SERV',\n",
    "         'LOITERING', 'ADMINISTRATIVE CODES']\n",
    "\n",
    "# categorize remaining offenses as other\n",
    "other = ['MISCELLANEOUS PENAL LAW', 'OFFENSES AGAINST MARRIAGE UNCL',\n",
    "         'OTHER STATE LAWS (NON PENAL LAW)', 'FORTUNE TELLING',\n",
    "         'NYS LAWS-UNCLASSIFIED VIOLATION', 'LOITERING/GAMBLING (CARDS, DIC',\n",
    "         'GAMBLING', 'OTHER STATE LAWS (NON PENAL LA', 'OTHER STATE LAWS',\n",
    "         'ANTICIPATORY OFFENSES', 'ESCAPE 3', 'AGRICULTURE & MRKTS LAW-UNCLASSIFIED',\n",
    "         'NYS LAWS-UNCLASSIFIED FELONY', 'UNAUTHORIZED USE OF A VEHICLE', 'OTHER']\n",
    "\n",
    "\n",
    "# combine all under a new column\n",
    "offenses = ['PROPERTY', 'SEXUAL', 'DRUGS/ALCOHOL', 'PERSONAL', 'ADMINISTRATIVE']\n",
    "\n",
    "conditions = [(df['OFNS_DESC'].isin(prop)),\n",
    "              (df['OFNS_DESC'].isin(sexual)),\n",
    "              (df['OFNS_DESC'].isin(drug_alch)),\n",
    "              (df['OFNS_DESC'].isin(personal)),\n",
    "              (df['OFNS_DESC'].isin(admin))]\n",
    "\n",
    "df = df.withColumn('OFNS_CATS', when(conditions[0], offenses[0])\n",
    "                   .when(conditions[1], offenses[1])\n",
    "                   .when(conditions[2], offenses[2])\n",
    "                   .when(conditions[3], offenses[3])\n",
    "                   .when(conditions[4], offenses[4])\n",
    "                   .otherwise('OTHER'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f8025b3f-023d-4c12-baff-168379f2f15b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# fix datatypes of categorical columns\n",
    "categorical_columns = set(df.columns) - set(['CMPLNT_NUM', 'RPT_DT', 'Latitude', 'Longitude', 'CMPLNT_DT'])\n",
    "for column in categorical_columns:\n",
    "    df = df.withColumn(column, col(column).cast('string'))\n",
    "\n",
    "# set the order of some categorical columns so the visualizations in EDA will be consistent\n",
    "df = df.withColumn('LAW_CAT_CD', df['LAW_CAT_CD'].cast('string').cast('string')\n",
    "                   .cast(\"string\")).orderBy(df['LAW_CAT_CD'].cast(\"string\").isin(['VIOLATION', 'MISDEMEANOR', 'FELONY']).desc())\n",
    "df = df.withColumn('SUSP_SEX', df['SUSP_SEX'].cast('string').cast('string')\n",
    "                   .cast(\"string\")).orderBy(df['SUSP_SEX'].cast(\"string\").isin(['FEMALE', 'MALE', 'UNKNOWN']).desc())\n",
    "df = df.withColumn('VIC_SEX', df['VIC_SEX'].cast('string').cast('string')\n",
    "                   .cast(\"string\")).orderBy(df['VIC_SEX'].cast(\"string\").isin(['FEMALE', 'MALE', 'BUSINESS/ORGANIZATION', 'UNKNOWN']).desc())\n",
    "df = df.withColumn('VIC_AGE_GROUP', df['VIC_AGE_GROUP'].cast('string').cast('string')\n",
    "                   .cast(\"string\")).orderBy(df['VIC_AGE_GROUP'].cast(\"string\").isin(['<18', '18-24', '25-44', '45-64', '65+', 'UNKNOWN']).desc())\n",
    "df = df.withColumn('SUSP_AGE_GROUP', df['SUSP_AGE_GROUP'].cast('string').cast('string')\n",
    "                   .cast(\"string\")).orderBy(df['SUSP_AGE_GROUP'].cast(\"string\").isin(['<18', '18-24', '25-44', '45-64', '65+', 'UNKNOWN']).desc())\n",
    "df = df.withColumn('OFNS_CATS', df['OFNS_CATS'].cast('string').cast('string')\n",
    "                   .cast(\"string\")).orderBy(df['OFNS_CATS'].cast(\"string\").isin(['PROPERTY', 'PERSONAL', 'SEXUAL', 'ADMINISTRATIVE', 'DRUGS/ALCOHOL', 'OTHER']).desc())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a38f425b-e1d4-44d5-b032-54b430622419",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, to_date, to_timestamp\n",
    "\n",
    "# Convert string columns to date and timestamp types\n",
    "df = df.withColumn('CMPLNT_FR_DT', to_date(col('CMPLNT_FR_DT'), 'MM/dd/yyyy'))\n",
    "df = df.withColumn('RPT_DT', to_date(col('RPT_DT'), 'MM/dd/yyyy'))\n",
    "\n",
    "# Convert string columns to integer types\n",
    "int_cols = ['ADDR_PCT_CD', 'KY_CD', 'PD_CD', 'JURISDICTION_CODE', 'X_COORD_CD', 'Y_COORD_CD']\n",
    "for col_name in int_cols:\n",
    "    df_temp = df.withColumn(col_name, col(col_name).cast('integer'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "235aab17-6529-44a1-a525-85cf21816d80",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+-------------------+-----------+----------+-----+--------------------+-----+--------------------+----------------+-----------+---------+-----------------+--------------------+----------------+-----------------+----------+----------+--------------+--------------+--------+------------+-------------+--------------------+--------------------+-------------+--------------------+--------------------+---------+\n",
      "|CMPLNT_NUM|CMPLNT_FR_DT|       CMPLNT_FR_TM|ADDR_PCT_CD|    RPT_DT|KY_CD|           OFNS_DESC|PD_CD|             PD_DESC|CRM_ATPT_CPTD_CD| LAW_CAT_CD|  BORO_NM|LOC_OF_OCCUR_DESC|       PREM_TYP_DESC|      JURIS_DESC|JURISDICTION_CODE|X_COORD_CD|Y_COORD_CD|SUSP_AGE_GROUP|     SUSP_RACE|SUSP_SEX|    Latitude|    Longitude|             Lat_Lon|         PATROL_BORO|VIC_AGE_GROUP|            VIC_RACE|             VIC_SEX|OFNS_CATS|\n",
      "+----------+------------+-------------------+-----------+----------+-----+--------------------+-----+--------------------+----------------+-----------+---------+-----------------+--------------------+----------------+-----------------+----------+----------+--------------+--------------+--------+------------+-------------+--------------------+--------------------+-------------+--------------------+--------------------+---------+\n",
      "| 875225485|  2014-02-07|2023-05-08 00:35:00|         71|2014-02-09|  341|       PETIT LARCENY|  343|LARCENY,PETIT OF ...|       COMPLETED|MISDEMEANOR| BROOKLYN|         FRONT OF|    RESTAURANT/DINER|N.Y. POLICE DEPT|                0|   1000206|    182026|       UNKNOWN|         BLACK|    MALE|40.666289884|-73.942485963|(40.666289884, -7...|PATROL BORO BKLYN...|        25-44|               WHITE|                MALE| PROPERTY|\n",
      "| 691335970|  2007-11-21|2023-05-08 23:00:00|         81|2007-11-21|  106|      FELONY ASSAULT|  109|ASSAULT 2,1,UNCLA...|       ATTEMPTED|     FELONY| BROOKLYN|         FRONT OF|      GROCERY/BODEGA|N.Y. POLICE DEPT|                0|   1002194|    191297|       UNKNOWN|       UNKNOWN| UNKNOWN|40.691732872|-73.935295276|(40.691732872, -7...|PATROL BORO BKLYN...|      UNKNOWN|             UNKNOWN|BUSINESS/ORGANIZA...| PERSONAL|\n",
      "| 920742936|  2008-11-19|2023-05-08 17:00:00|         17|2008-11-19|  578|       HARRASSMENT 2|  637|HARASSMENT,SUBD 1...|       COMPLETED|  VIOLATION|MANHATTAN|           INSIDE|               OTHER|N.Y. POLICE DEPT|                0|    992029|    213332|         45-64|         BLACK|  FEMALE|  40.7522284|-73.971924858|(40.7522284, -73....|PATROL BORO MAN S...|        45-64|               BLACK|              FEMALE|   SEXUAL|\n",
      "| 473620940|  2008-08-15|2023-05-08 20:00:00|        115|2008-08-18|  110|GRAND LARCENY OF ...|  441|LARCENY,GRAND OF ...|       COMPLETED|     FELONY|   QUEENS|         FRONT OF|              STREET|N.Y. POLICE DEPT|                0|   1018212|    213827|       UNKNOWN|       UNKNOWN| UNKNOWN|40.753525252|-73.877420646|(40.753525252, -7...|PATROL BORO QUEEN...|        45-64|ASIAN / PACIFIC I...|              FEMALE| PROPERTY|\n",
      "| 368722734|  2010-04-27|2023-05-08 21:30:00|         40|2010-04-27|  106|      FELONY ASSAULT|  109|ASSAULT 2,1,UNCLA...|       COMPLETED|     FELONY|    BRONX|           INSIDE|RESIDENCE - APT. ...|N.Y. POLICE DEPT|                0|   1009213|    234813|         25-44|WHITE HISPANIC|    MALE|40.811156213|-73.909823201|(40.811156213, -7...|   PATROL BORO BRONX|        25-44|      WHITE HISPANIC|              FEMALE| PERSONAL|\n",
      "| 305192617|  2006-10-03|2023-05-08 21:00:00|         60|2006-10-04|  110|GRAND LARCENY OF ...|  441|LARCENY,GRAND OF ...|       COMPLETED|     FELONY| BROOKLYN|          UNKNOWN|              STREET|N.Y. POLICE DEPT|                0|    990449|    154997|       UNKNOWN|       UNKNOWN| UNKNOWN|40.592113178|-73.977681159|(40.592113178, -7...|PATROL BORO BKLYN...|        25-44|               WHITE|                MALE| PROPERTY|\n",
      "| 661827614|  2009-12-04|2023-05-08 19:15:00|          1|2009-12-04|  344|ASSAULT 3 & RELAT...|  113|MENACING,UNCLASSI...|       COMPLETED|MISDEMEANOR|MANHATTAN|          UNKNOWN|              STREET|N.Y. POLICE DEPT|                0|    981014|    197835|       UNKNOWN|         BLACK|    MALE|40.709695753|-74.011673625|(40.709695753, -7...|PATROL BORO MAN S...|        25-44|               BLACK|              FEMALE| PERSONAL|\n",
      "| 709010399|  2010-03-30|2023-05-08 10:00:00|        104|2010-03-30|  351|CRIMINAL MISCHIEF...|  259|CRIMINAL MISCHIEF...|       COMPLETED|MISDEMEANOR|   QUEENS|          UNKNOWN|              STREET|N.Y. POLICE DEPT|                0|   1010959|    194469|       UNKNOWN|       UNKNOWN| UNKNOWN|40.700417161|-73.903676078|(40.700417161, -7...|PATROL BORO QUEEN...|      UNKNOWN|             UNKNOWN|BUSINESS/ORGANIZA...| PROPERTY|\n",
      "| 344123822|  2010-09-08|2023-05-08 16:00:00|         43|2010-09-08|  344|ASSAULT 3 & RELAT...|  101|           ASSAULT 3|       COMPLETED|MISDEMEANOR|    BRONX|           INSIDE|RESIDENCE - APT. ...|N.Y. POLICE DEPT|                0|   1023548|    238402|         18-24|WHITE HISPANIC|    MALE|40.820954868|-73.858017409|(40.820954868, -7...|   PATROL BORO BRONX|        18-24|      WHITE HISPANIC|              FEMALE| PERSONAL|\n",
      "| 671647507|  2011-12-28|2023-05-08 02:00:00|        104|2011-12-28|  578|       HARRASSMENT 2|  638|HARASSMENT,SUBD 3...|       COMPLETED|  VIOLATION|   QUEENS|           INSIDE|         CHAIN STORE|N.Y. POLICE DEPT|                0|   1019645|    199168|         18-24|         WHITE|    MALE|40.713284318|-73.872325566|(40.713284318, -7...|PATROL BORO QUEEN...|        25-44|ASIAN / PACIFIC I...|                MALE|   SEXUAL|\n",
      "+----------+------------+-------------------+-----------+----------+-----+--------------------+-----+--------------------+----------------+-----------+---------+-----------------+--------------------+----------------+-----------------+----------+----------+--------------+--------------+--------+------------+-------------+--------------------+--------------------+-------------+--------------------+--------------------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "13ff4822-bded-4196-95e5-c8f3d99ba588",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1945988"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8566de0e-4218-4dbc-b106-34042184675d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.drop('CMPLNT_FR_TM_timestamp', 'CMPLNT_FR_TM_double', \"JURISDICTION_CODE\", \"JURIS_DESC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "04645ddd-ffc1-4b0a-a15d-f1b169a7062a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CMPLNT_NUM: integer (nullable = true)\n",
      " |-- CMPLNT_FR_DT: date (nullable = true)\n",
      " |-- CMPLNT_FR_TM: string (nullable = true)\n",
      " |-- ADDR_PCT_CD: string (nullable = true)\n",
      " |-- RPT_DT: date (nullable = true)\n",
      " |-- KY_CD: string (nullable = true)\n",
      " |-- OFNS_DESC: string (nullable = false)\n",
      " |-- PD_CD: string (nullable = true)\n",
      " |-- PD_DESC: string (nullable = false)\n",
      " |-- CRM_ATPT_CPTD_CD: string (nullable = false)\n",
      " |-- LAW_CAT_CD: string (nullable = false)\n",
      " |-- BORO_NM: string (nullable = false)\n",
      " |-- LOC_OF_OCCUR_DESC: string (nullable = false)\n",
      " |-- PREM_TYP_DESC: string (nullable = false)\n",
      " |-- X_COORD_CD: string (nullable = true)\n",
      " |-- Y_COORD_CD: string (nullable = true)\n",
      " |-- SUSP_AGE_GROUP: string (nullable = false)\n",
      " |-- SUSP_RACE: string (nullable = false)\n",
      " |-- SUSP_SEX: string (nullable = false)\n",
      " |-- Latitude: double (nullable = true)\n",
      " |-- Longitude: double (nullable = true)\n",
      " |-- Lat_Lon: string (nullable = false)\n",
      " |-- PATROL_BORO: string (nullable = false)\n",
      " |-- VIC_AGE_GROUP: string (nullable = false)\n",
      " |-- VIC_RACE: string (nullable = false)\n",
      " |-- VIC_SEX: string (nullable = false)\n",
      " |-- OFNS_CATS: string (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf575072-5d60-4c43-912d-85711e8efc56",
   "metadata": {},
   "source": [
    "## Merge with nyc neighbourhoods( add neighbourhood col in original dataset )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "287b035d-cf4c-4fc3-91d2-ba215da7f566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pyspark in c:\\users\\shlok\\appdata\\roaming\\python\\python311\\site-packages (3.4.0)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in c:\\users\\shlok\\appdata\\roaming\\python\\python311\\site-packages (from pyspark) (0.10.9.7)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pymongo in c:\\users\\shlok\\appdata\\roaming\\python\\python311\\site-packages (4.3.3)\n",
      "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in c:\\users\\shlok\\appdata\\roaming\\python\\python311\\site-packages (from pymongo) (2.3.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in c:\\users\\shlok\\appdata\\roaming\\python\\python311\\site-packages (2.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\shlok\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\shlok\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\shlok\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\shlok\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\shlok\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: geopy in c:\\users\\shlok\\appdata\\roaming\\python\\python311\\site-packages (2.3.0)\n",
      "Requirement already satisfied: geographiclib<3,>=1.52 in c:\\users\\shlok\\appdata\\roaming\\python\\python311\\site-packages (from geopy) (2.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: folium in c:\\users\\shlok\\appdata\\roaming\\python\\python311\\site-packages (0.14.0)\n",
      "Requirement already satisfied: branca>=0.6.0 in c:\\users\\shlok\\appdata\\roaming\\python\\python311\\site-packages (from folium) (0.6.0)\n",
      "Requirement already satisfied: jinja2>=2.9 in c:\\users\\shlok\\appdata\\roaming\\python\\python311\\site-packages (from folium) (3.1.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\shlok\\appdata\\roaming\\python\\python311\\site-packages (from folium) (1.24.3)\n",
      "Requirement already satisfied: requests in c:\\users\\shlok\\appdata\\roaming\\python\\python311\\site-packages (from folium) (2.30.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\shlok\\appdata\\roaming\\python\\python311\\site-packages (from jinja2>=2.9->folium) (2.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\shlok\\appdata\\roaming\\python\\python311\\site-packages (from requests->folium) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shlok\\appdata\\roaming\\python\\python311\\site-packages (from requests->folium) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\shlok\\appdata\\roaming\\python\\python311\\site-packages (from requests->folium) (2.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shlok\\appdata\\roaming\\python\\python311\\site-packages (from requests->folium) (2022.12.7)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: haversine in c:\\users\\shlok\\appdata\\roaming\\python\\python311\\site-packages (2.8.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark\n",
    "!pip install pymongo\n",
    "!pip install pandas\n",
    "!pip install geopy\n",
    "!pip install folium\n",
    "!pip install haversine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6d0c29e4-b3bb-4fb1-ad28-de0f95b5df83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+-------------------+-----------+----------+-----+--------------------+-----+--------------------+----------------+-----------+---------+-----------------+--------------------+----------+----------+--------------+--------------+--------+------------+-------------+--------------------+--------------------+-------------+--------------------+--------------------+--------------+\n",
      "|CMPLNT_NUM|CMPLNT_FR_DT|       CMPLNT_FR_TM|ADDR_PCT_CD|    RPT_DT|KY_CD|           OFNS_DESC|PD_CD|             PD_DESC|CRM_ATPT_CPTD_CD| LAW_CAT_CD|  BORO_NM|LOC_OF_OCCUR_DESC|       PREM_TYP_DESC|X_COORD_CD|Y_COORD_CD|SUSP_AGE_GROUP|     SUSP_RACE|SUSP_SEX|    Latitude|    Longitude|             Lat_Lon|         PATROL_BORO|VIC_AGE_GROUP|            VIC_RACE|             VIC_SEX|     OFNS_CATS|\n",
      "+----------+------------+-------------------+-----------+----------+-----+--------------------+-----+--------------------+----------------+-----------+---------+-----------------+--------------------+----------+----------+--------------+--------------+--------+------------+-------------+--------------------+--------------------+-------------+--------------------+--------------------+--------------+\n",
      "| 573454323|  2013-08-05|2023-05-08 06:15:00|         28|2013-08-05|  341|       PETIT LARCENY|  321|LARCENY,PETIT FRO...|       COMPLETED|MISDEMEANOR|MANHATTAN|         FRONT OF|              STREET|    997486|    232024|       UNKNOWN|       UNKNOWN| UNKNOWN|40.803526529|-73.952192199|(40.803526529, -7...|PATROL BORO MAN N...|        45-64|               WHITE|                MALE|      PROPERTY|\n",
      "| 344123822|  2010-09-08|2023-05-08 16:00:00|         43|2010-09-08|  344|ASSAULT 3 & RELAT...|  101|           ASSAULT 3|       COMPLETED|MISDEMEANOR|    BRONX|           INSIDE|RESIDENCE - APT. ...|   1023548|    238402|         18-24|WHITE HISPANIC|    MALE|40.820954868|-73.858017409|(40.820954868, -7...|   PATROL BORO BRONX|        18-24|      WHITE HISPANIC|              FEMALE|      PERSONAL|\n",
      "| 691335970|  2007-11-21|2023-05-08 23:00:00|         81|2007-11-21|  106|      FELONY ASSAULT|  109|ASSAULT 2,1,UNCLA...|       ATTEMPTED|     FELONY| BROOKLYN|         FRONT OF|      GROCERY/BODEGA|   1002194|    191297|       UNKNOWN|       UNKNOWN| UNKNOWN|40.691732872|-73.935295276|(40.691732872, -7...|PATROL BORO BKLYN...|      UNKNOWN|             UNKNOWN|BUSINESS/ORGANIZA...|      PERSONAL|\n",
      "| 484808987|  2006-11-17|2023-05-08 22:00:00|         63|2006-11-19|  109|       GRAND LARCENY|  457|LARCENY,GRAND OF ...|       COMPLETED|     FELONY| BROOKLYN|           INSIDE|              STREET|   1006250|    167033|       UNKNOWN|       UNKNOWN| UNKNOWN| 40.62512439|-73.920748481|(40.62512439, -73...|PATROL BORO BKLYN...|        25-44|               BLACK|              FEMALE|      PROPERTY|\n",
      "| 368722734|  2010-04-27|2023-05-08 21:30:00|         40|2010-04-27|  106|      FELONY ASSAULT|  109|ASSAULT 2,1,UNCLA...|       COMPLETED|     FELONY|    BRONX|           INSIDE|RESIDENCE - APT. ...|   1009213|    234813|         25-44|WHITE HISPANIC|    MALE|40.811156213|-73.909823201|(40.811156213, -7...|   PATROL BORO BRONX|        25-44|      WHITE HISPANIC|              FEMALE|      PERSONAL|\n",
      "| 929192414|  2009-09-01|2023-05-08 04:30:00|         26|2009-09-01|  351|CRIMINAL MISCHIEF...|  256|MISCHIEF, CRIMINA...|       COMPLETED|MISDEMEANOR|MANHATTAN|          UNKNOWN|              STREET|    996080|    233261|       UNKNOWN|       UNKNOWN| UNKNOWN|40.806923748|-73.957268578|(40.806923748, -7...|PATROL BORO MAN N...|        25-44|             UNKNOWN|              FEMALE|      PROPERTY|\n",
      "| 473620940|  2008-08-15|2023-05-08 20:00:00|        115|2008-08-18|  110|GRAND LARCENY OF ...|  441|LARCENY,GRAND OF ...|       COMPLETED|     FELONY|   QUEENS|         FRONT OF|              STREET|   1018212|    213827|       UNKNOWN|       UNKNOWN| UNKNOWN|40.753525252|-73.877420646|(40.753525252, -7...|PATROL BORO QUEEN...|        45-64|ASIAN / PACIFIC I...|              FEMALE|      PROPERTY|\n",
      "| 967908827|  2006-03-23|2023-05-08 10:29:00|        109|2006-09-11|  109|       GRAND LARCENY|  405|LARCENY,GRAND BY ...|       COMPLETED|     FELONY|   QUEENS|           INSIDE|  STORE UNCLASSIFIED|   1027377|    219665|       UNKNOWN|       UNKNOWN| UNKNOWN| 40.76950909|-73.844303547|(40.76950909, -73...|PATROL BORO QUEEN...|        25-44|             UNKNOWN|              FEMALE|      PROPERTY|\n",
      "| 664089795|  2008-04-14|2023-05-08 04:14:00|         84|2008-04-14|  341|       PETIT LARCENY|  338|LARCENY,PETIT FRO...|       COMPLETED|MISDEMEANOR| BROOKLYN|           INSIDE|GYM/FITNESS FACILITY|    986598|    190448|       UNKNOWN|       UNKNOWN| UNKNOWN| 40.68942044|-73.991534838|(40.68942044, -73...|PATROL BORO BKLYN...|        25-44|               WHITE|              FEMALE|      PROPERTY|\n",
      "| 659306557|  2009-05-09|2023-05-08 13:00:00|         72|2009-05-13|  351|CRIMINAL MISCHIEF...|  259|CRIMINAL MISCHIEF...|       COMPLETED|MISDEMEANOR| BROOKLYN|          REAR OF|     RESIDENCE-HOUSE|    989921|    178169|       UNKNOWN|       UNKNOWN| UNKNOWN|40.655715829|-73.979562825|(40.655715829, -7...|PATROL BORO BKLYN...|          65+|               WHITE|              FEMALE|      PROPERTY|\n",
      "| 305192617|  2006-10-03|2023-05-08 21:00:00|         60|2006-10-04|  110|GRAND LARCENY OF ...|  441|LARCENY,GRAND OF ...|       COMPLETED|     FELONY| BROOKLYN|          UNKNOWN|              STREET|    990449|    154997|       UNKNOWN|       UNKNOWN| UNKNOWN|40.592113178|-73.977681159|(40.592113178, -7...|PATROL BORO BKLYN...|        25-44|               WHITE|                MALE|      PROPERTY|\n",
      "| 358456726|  2010-03-29|2023-05-08 12:20:00|        114|2010-03-29|  359|OFFENSES AGAINST ...|  749|VIOLATION OF ORDE...|       COMPLETED|MISDEMEANOR|   QUEENS|         FRONT OF|     RESIDENCE-HOUSE|   1009625|    223300|         45-64|       UNKNOWN|  FEMALE|40.779554986|-73.908378361|(40.779554986, -7...|PATROL BORO QUEEN...|          <18|               WHITE|                MALE|ADMINISTRATIVE|\n",
      "| 178533299|  2010-04-13|2023-05-08 19:00:00|        115|2010-04-13|  106|      FELONY ASSAULT|  109|ASSAULT 2,1,UNCLA...|       COMPLETED|     FELONY|   QUEENS|         FRONT OF|              STREET|   1017493|    211832|       UNKNOWN|       UNKNOWN|    MALE|40.748052218|-73.880025628|(40.748052218, -7...|PATROL BORO QUEEN...|        25-44|      WHITE HISPANIC|                MALE|      PERSONAL|\n",
      "| 878669886|  2010-06-08|2023-05-08 00:15:00|        106|2010-06-08|  106|      FELONY ASSAULT|  109|ASSAULT 2,1,UNCLA...|       COMPLETED|     FELONY|   QUEENS|         FRONT OF|              STREET|   1029579|    187863|       UNKNOWN|       UNKNOWN| UNKNOWN|40.682209456|-73.836568068|(40.682209456, -7...|PATROL BORO QUEEN...|          <18|      WHITE HISPANIC|                MALE|      PERSONAL|\n",
      "| 709010399|  2010-03-30|2023-05-08 10:00:00|        104|2010-03-30|  351|CRIMINAL MISCHIEF...|  259|CRIMINAL MISCHIEF...|       COMPLETED|MISDEMEANOR|   QUEENS|          UNKNOWN|              STREET|   1010959|    194469|       UNKNOWN|       UNKNOWN| UNKNOWN|40.700417161|-73.903676078|(40.700417161, -7...|PATROL BORO QUEEN...|      UNKNOWN|             UNKNOWN|BUSINESS/ORGANIZA...|      PROPERTY|\n",
      "| 175336748|  2011-04-16|2023-05-08 18:25:00|         41|2011-05-03|  126|MISCELLANEOUS PEN...|  779|PUBLIC ADMINISTRA...|       COMPLETED|     FELONY|    BRONX|           INSIDE|               OTHER|   1017934|    232221|       UNKNOWN|       UNKNOWN| UNKNOWN|40.804012949|-73.878331833|(40.804012949, -7...|   PATROL BORO BRONX|      UNKNOWN|             UNKNOWN|             UNKNOWN|         OTHER|\n",
      "| 588720339|  2011-05-04|2023-05-08 16:35:00|         68|2011-05-04|  341|       PETIT LARCENY|  313|LARCENY,PETIT BY ...|       COMPLETED|MISDEMEANOR| BROOKLYN|          UNKNOWN|              STREET|    976298|    165920|       UNKNOWN|       UNKNOWN|    MALE|40.622093181|-74.028646479|(40.622093181, -7...|PATROL BORO BKLYN...|        18-24|               WHITE|                MALE|      PROPERTY|\n",
      "| 260081059|  2009-05-12|2023-05-08 19:20:00|         67|2009-05-12|  361|OFF. AGNST PUB OR...|  639|AGGRAVATED HARASS...|       COMPLETED|MISDEMEANOR| BROOKLYN|           INSIDE|RESIDENCE - APT. ...|    998545|    177640|       UNKNOWN|BLACK HISPANIC|    MALE|40.654254118| -73.94848255|(40.654254118, -7...|PATROL BORO BKLYN...|        25-44|               BLACK|                MALE|ADMINISTRATIVE|\n",
      "| 671647507|  2011-12-28|2023-05-08 02:00:00|        104|2011-12-28|  578|       HARRASSMENT 2|  638|HARASSMENT,SUBD 3...|       COMPLETED|  VIOLATION|   QUEENS|           INSIDE|         CHAIN STORE|   1019645|    199168|         18-24|         WHITE|    MALE|40.713284318|-73.872325566|(40.713284318, -7...|PATROL BORO QUEEN...|        25-44|ASIAN / PACIFIC I...|                MALE|        SEXUAL|\n",
      "| 885973724|  2007-04-30|2023-05-08 08:30:00|         83|2007-04-30|  105|             ROBBERY|  384|ROBBERY,POCKETBOO...|       COMPLETED|     FELONY| BROOKLYN|      OPPOSITE OF|PARKING LOT/GARAG...|   1003970|    193919|       UNKNOWN|         BLACK|    MALE|40.698925874|-73.928883336|(40.698925874, -7...|PATROL BORO BKLYN...|          <18|      BLACK HISPANIC|              FEMALE|      PROPERTY|\n",
      "+----------+------------+-------------------+-----------+----------+-----+--------------------+-----+--------------------+----------------+-----------+---------+-----------------+--------------------+----------+----------+--------------+--------------+--------+------------+-------------+--------------------+--------------------+-------------+--------------------+--------------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o1344.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 292.0 failed 1 times, most recent failure: Lost task 0.0 in stage 292.0 (TID 1990) (Beast.lan executor driver): org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:192)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:109)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:166)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\tat java.lang.Thread.run(Unknown Source)\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.net.DualStackPlainSocketImpl.waitForNewConnection(Native Method)\r\n\tat java.net.DualStackPlainSocketImpl.socketAccept(Unknown Source)\r\n\tat java.net.AbstractPlainSocketImpl.accept(Unknown Source)\r\n\tat java.net.PlainSocketImpl.accept(Unknown Source)\r\n\tat java.net.ServerSocket.implAccept(Unknown Source)\r\n\tat java.net.ServerSocket.accept(Unknown Source)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:179)\r\n\t... 30 more\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2785)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2721)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2720)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2720)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1206)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1206)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1206)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2984)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2923)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2912)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:971)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2263)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2284)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2303)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:530)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:483)\r\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:61)\r\n\tat org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:4177)\r\n\tat org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:3161)\r\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:4167)\r\n\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:526)\r\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:4165)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:118)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:195)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:103)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:827)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:65)\r\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:4165)\r\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:3161)\r\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:3382)\r\n\tat org.apache.spark.sql.Dataset.getRows(Dataset.scala:284)\r\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:323)\r\n\tat sun.reflect.GeneratedMethodAccessor136.invoke(Unknown Source)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\r\n\tat java.lang.reflect.Method.invoke(Unknown Source)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.lang.Thread.run(Unknown Source)\r\nCaused by: org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:192)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:109)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:166)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\t... 1 more\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.net.DualStackPlainSocketImpl.waitForNewConnection(Native Method)\r\n\tat java.net.DualStackPlainSocketImpl.socketAccept(Unknown Source)\r\n\tat java.net.AbstractPlainSocketImpl.accept(Unknown Source)\r\n\tat java.net.PlainSocketImpl.accept(Unknown Source)\r\n\tat java.net.ServerSocket.implAccept(Unknown Source)\r\n\tat java.net.ServerSocket.accept(Unknown Source)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:179)\r\n\t... 30 more\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 36\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# show the dataframes\u001b[39;00m\n\u001b[0;32m     35\u001b[0m df\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m---> 36\u001b[0m \u001b[43mneighborhoodsDF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pyspark\\sql\\dataframe.py:899\u001b[0m, in \u001b[0;36mDataFrame.show\u001b[1;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkTypeError(\n\u001b[0;32m    894\u001b[0m         error_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNOT_BOOL\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    895\u001b[0m         message_parameters\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvertical\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(vertical)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m},\n\u001b[0;32m    896\u001b[0m     )\n\u001b[0;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(truncate, \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m truncate:\n\u001b[1;32m--> 899\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshowString\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvertical\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    901\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pyspark\\errors\\exceptions\\captured.py:169\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 169\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    170\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    171\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\py4j\\protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[1;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[0;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o1344.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 292.0 failed 1 times, most recent failure: Lost task 0.0 in stage 292.0 (TID 1990) (Beast.lan executor driver): org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:192)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:109)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:166)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\tat java.lang.Thread.run(Unknown Source)\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.net.DualStackPlainSocketImpl.waitForNewConnection(Native Method)\r\n\tat java.net.DualStackPlainSocketImpl.socketAccept(Unknown Source)\r\n\tat java.net.AbstractPlainSocketImpl.accept(Unknown Source)\r\n\tat java.net.PlainSocketImpl.accept(Unknown Source)\r\n\tat java.net.ServerSocket.implAccept(Unknown Source)\r\n\tat java.net.ServerSocket.accept(Unknown Source)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:179)\r\n\t... 30 more\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2785)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2721)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2720)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2720)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1206)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1206)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1206)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2984)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2923)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2912)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:971)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2263)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2284)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2303)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:530)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:483)\r\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:61)\r\n\tat org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:4177)\r\n\tat org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:3161)\r\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:4167)\r\n\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:526)\r\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:4165)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:118)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:195)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:103)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:827)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:65)\r\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:4165)\r\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:3161)\r\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:3382)\r\n\tat org.apache.spark.sql.Dataset.getRows(Dataset.scala:284)\r\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:323)\r\n\tat sun.reflect.GeneratedMethodAccessor136.invoke(Unknown Source)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\r\n\tat java.lang.reflect.Method.invoke(Unknown Source)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.lang.Thread.run(Unknown Source)\r\nCaused by: org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:192)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:109)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:166)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\t... 1 more\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.net.DualStackPlainSocketImpl.waitForNewConnection(Native Method)\r\n\tat java.net.DualStackPlainSocketImpl.socketAccept(Unknown Source)\r\n\tat java.net.AbstractPlainSocketImpl.accept(Unknown Source)\r\n\tat java.net.PlainSocketImpl.accept(Unknown Source)\r\n\tat java.net.ServerSocket.implAccept(Unknown Source)\r\n\tat java.net.ServerSocket.accept(Unknown Source)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:179)\r\n\t... 30 more\r\n"
     ]
    }
   ],
   "source": [
    "# download the JSON file using requests library\n",
    "import requests\n",
    "url = 'https://cocl.us/new_york_dataset'\n",
    "response = requests.get(url)\n",
    "newyork_data = response.json()\n",
    "\n",
    "# extract neighborhoods data\n",
    "neighborhoods_data = newyork_data['features']\n",
    "\n",
    "# create a list of dictionaries to store the data\n",
    "neighborhoods_list = []\n",
    "\n",
    "# populate list with neighborhoods data\n",
    "for data in neighborhoods_data:\n",
    "    borough = data['properties']['borough']\n",
    "    neighborhood_name = data['properties']['name']\n",
    "    neighborhood_lat = data['geometry']['coordinates'][1]\n",
    "    neighborhood_lon = data['geometry']['coordinates'][0]\n",
    "    neighborhoods_list.append({'Borough': borough,\n",
    "                               'Neighborhood': neighborhood_name,\n",
    "                               'Latitude': neighborhood_lat,\n",
    "                               'Longitude': neighborhood_lon})\n",
    "\n",
    "# create a DataFrame from the list of dictionaries\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType\n",
    "schema = StructType([\n",
    "    StructField('Borough', StringType(), True),\n",
    "    StructField('Neighborhood', StringType(), True),\n",
    "    StructField('Latitude', DoubleType(), True),\n",
    "    StructField('Longitude', DoubleType(), True)\n",
    "])\n",
    "neighborhoodsDF = spark.createDataFrame(neighborhoods_list, schema=schema)\n",
    "\n",
    "# show the dataframes\n",
    "df.show()\n",
    "neighborhoodsDF.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3175fd8-40d7-474f-8e87-7f64e9ab8b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, lower\n",
    "\n",
    "neighborCrimeDF = complaintsDF.join(\n",
    "    neighborhoodsDF.select([\n",
    "        \"Borough\",\n",
    "        \"Neighborhood\",\n",
    "        col(\"Latitude\").alias(\"NLatitude\"),\n",
    "        col(\"Longitude\").alias(\"NLongitude\")\n",
    "    ]),\n",
    "    lower(complaintsDF.BORO_NM) == lower(neighborhoodsDF.Borough),\n",
    "    \"left\"\n",
    ")\n",
    "neighborCrimeDF.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4d20ba-ea89-433b-aa32-b533e7ea48b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, ArrayType\n",
    "from haversine import haversine\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "# define UDFs to calculate distance using haversine formula\n",
    "udf_haversine = udf(lambda x, y: haversine(x, y, unit='mi') if x is not None and y is not None else None, DoubleType())\n",
    "udf_string2array = udf(lambda lat, long: [float(lat), float(long)] if lat is not None and long is not None else None, ArrayType(DoubleType()))\n",
    "# create new columns with latitude and longitude as arrays, and distance between crime location and neighborhood\n",
    "neighborCrimeDF2 = neighborCrimeDF \\\n",
    "    .withColumn(\"LatLong\", udf_string2array(\"Latitude\", \"Longitude\")) \\\n",
    "    .withColumn(\"NLatLong\", udf_string2array(\"NLatitude\", \"NLongitude\")) \\\n",
    "    .withColumn(\"Distance\", udf_haversine(\"LatLong\", \"NLatLong\"))\n",
    "    # use window function to get the nearest neighborhood for each crime\n",
    "window = Window.partitionBy(\"CMPLNT_NUM\").orderBy(F.col(\"Distance\").asc())\n",
    "NCDF = neighborCrimeDF2 \\\n",
    "    .withColumn(\"DistanceRank\", F.rank().over(window)) \\\n",
    "    .filter(F.col(\"DistanceRank\") == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aef305d-3b99-4844-91cc-77b84ca70a8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34caf304-567b-4580-a33a-1045f79cae87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1945988"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4834ea20-c48a-47db-901f-f49a573859b3",
   "metadata": {},
   "source": [
    "## Store cleaned data to mongoDB database for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "137aea45-76bc-4c56-9285-cdb92c28aa37",
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 25.0 failed 1 times, most recent failure: Lost task 0.0 in stage 25.0 (TID 217) (Beast.lan executor driver): org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:192)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:109)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:166)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\tat java.lang.Thread.run(Unknown Source)\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.net.DualStackPlainSocketImpl.waitForNewConnection(Native Method)\r\n\tat java.net.DualStackPlainSocketImpl.socketAccept(Unknown Source)\r\n\tat java.net.AbstractPlainSocketImpl.accept(Unknown Source)\r\n\tat java.net.PlainSocketImpl.accept(Unknown Source)\r\n\tat java.net.ServerSocket.implAccept(Unknown Source)\r\n\tat java.net.ServerSocket.accept(Unknown Source)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:179)\r\n\t... 15 more\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2785)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2721)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2720)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2720)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1206)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1206)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1206)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2984)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2923)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2912)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:971)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2263)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2284)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2303)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2328)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1019)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:405)\r\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1018)\r\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:193)\r\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\r\n\tat java.lang.reflect.Method.invoke(Unknown Source)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.lang.Thread.run(Unknown Source)\r\nCaused by: org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:192)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:109)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:166)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\t... 1 more\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.net.DualStackPlainSocketImpl.waitForNewConnection(Native Method)\r\n\tat java.net.DualStackPlainSocketImpl.socketAccept(Unknown Source)\r\n\tat java.net.AbstractPlainSocketImpl.accept(Unknown Source)\r\n\tat java.net.PlainSocketImpl.accept(Unknown Source)\r\n\tat java.net.ServerSocket.implAccept(Unknown Source)\r\n\tat java.net.ServerSocket.accept(Unknown Source)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:179)\r\n\t... 15 more\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m     collection\u001b[38;5;241m.\u001b[39minsert_many(rows)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# insert the data into MongoDB\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrdd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masDict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforeachPartition\u001b[49m\u001b[43m(\u001b[49m\u001b[43minsert_partition\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pyspark\\rdd.py:1782\u001b[0m, in \u001b[0;36mRDD.foreachPartition\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m   1779\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   1780\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28miter\u001b[39m([])\n\u001b[1;32m-> 1782\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmapPartitions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcount\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pyspark\\rdd.py:2297\u001b[0m, in \u001b[0;36mRDD.count\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2276\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcount\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[0;32m   2277\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2278\u001b[0m \u001b[38;5;124;03m    Return the number of elements in this RDD.\u001b[39;00m\n\u001b[0;32m   2279\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2295\u001b[0m \u001b[38;5;124;03m    3\u001b[39;00m\n\u001b[0;32m   2296\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2297\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmapPartitions\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pyspark\\rdd.py:2272\u001b[0m, in \u001b[0;36mRDD.sum\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2251\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msum\u001b[39m(\u001b[38;5;28mself\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRDD[NumberOrArray]\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumberOrArray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   2252\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2253\u001b[0m \u001b[38;5;124;03m    Add up the elements in this RDD.\u001b[39;00m\n\u001b[0;32m   2254\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2270\u001b[0m \u001b[38;5;124;03m    6.0\u001b[39;00m\n\u001b[0;32m   2271\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2272\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmapPartitions\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfold\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[return-value]\u001b[39;49;00m\n\u001b[0;32m   2273\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\n\u001b[0;32m   2274\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pyspark\\rdd.py:2025\u001b[0m, in \u001b[0;36mRDD.fold\u001b[1;34m(self, zeroValue, op)\u001b[0m\n\u001b[0;32m   2020\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m acc\n\u001b[0;32m   2022\u001b[0m \u001b[38;5;66;03m# collecting result of mapPartitions here ensures that the copy of\u001b[39;00m\n\u001b[0;32m   2023\u001b[0m \u001b[38;5;66;03m# zeroValue provided to each partition is unique from the one provided\u001b[39;00m\n\u001b[0;32m   2024\u001b[0m \u001b[38;5;66;03m# to the final reduce call\u001b[39;00m\n\u001b[1;32m-> 2025\u001b[0m vals \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmapPartitions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m reduce(op, vals, zeroValue)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pyspark\\rdd.py:1814\u001b[0m, in \u001b[0;36mRDD.collect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1812\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SCCallSiteSync(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext):\n\u001b[0;32m   1813\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mctx\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1814\u001b[0m     sock_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPythonRDD\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollectAndServe\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jrdd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrdd\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1815\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(_load_from_socket(sock_info, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jrdd_deserializer))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pyspark\\errors\\exceptions\\captured.py:169\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 169\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    170\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    171\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\py4j\\protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[1;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[0;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 25.0 failed 1 times, most recent failure: Lost task 0.0 in stage 25.0 (TID 217) (Beast.lan executor driver): org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:192)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:109)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:166)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\tat java.lang.Thread.run(Unknown Source)\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.net.DualStackPlainSocketImpl.waitForNewConnection(Native Method)\r\n\tat java.net.DualStackPlainSocketImpl.socketAccept(Unknown Source)\r\n\tat java.net.AbstractPlainSocketImpl.accept(Unknown Source)\r\n\tat java.net.PlainSocketImpl.accept(Unknown Source)\r\n\tat java.net.ServerSocket.implAccept(Unknown Source)\r\n\tat java.net.ServerSocket.accept(Unknown Source)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:179)\r\n\t... 15 more\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2785)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2721)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2720)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2720)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1206)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1206)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1206)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2984)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2923)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2912)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:971)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2263)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2284)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2303)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2328)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1019)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:405)\r\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1018)\r\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:193)\r\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\r\n\tat java.lang.reflect.Method.invoke(Unknown Source)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.lang.Thread.run(Unknown Source)\r\nCaused by: org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:192)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:109)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:166)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\t... 1 more\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.net.DualStackPlainSocketImpl.waitForNewConnection(Native Method)\r\n\tat java.net.DualStackPlainSocketImpl.socketAccept(Unknown Source)\r\n\tat java.net.AbstractPlainSocketImpl.accept(Unknown Source)\r\n\tat java.net.PlainSocketImpl.accept(Unknown Source)\r\n\tat java.net.ServerSocket.implAccept(Unknown Source)\r\n\tat java.net.ServerSocket.accept(Unknown Source)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:179)\r\n\t... 15 more\r\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pymongo\n",
    "from bson import json_util\n",
    "\n",
    "# define the function to insert a partition into MongoDB\n",
    "def insert_partition(rows):\n",
    "    client = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "    db = client[\"NYPD\"]\n",
    "    collection = db[\"NYPD_Cleaned\"]\n",
    "    collection.insert_many(rows)\n",
    "# insert the data into MongoDB\n",
    "df.rdd.map(lambda row: row.asDict()).foreachPartition(insert_partition)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a0d752-93a5-4f1a-b1ee-33d9da210799",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
